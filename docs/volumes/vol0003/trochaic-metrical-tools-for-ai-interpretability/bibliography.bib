@article{heuser_generative_2025,
	title = {Generative {Aesthetics}: {On} formal stuckness in {AI} verse},
	volume = {10},
	number = {3},
	journal = {Journal of Cultural Analytics},
	author = {Heuser, Ryan},
	month = oct,
	year = {2025},
}

@incollection{tarlinskaja_what_2006,
	address = {Berlin},
	series = {Phonology and {Phonetics}},
	title = {What is `{Metricality}'? {English} iambic pentameter},
	number = {11},
	booktitle = {Formal {Approaches} to {Poetry}: {Recent} {Developments} in {Metrics}},
	publisher = {Mouton de Gruyter},
	author = {Tarlinskaja, Marina},
	editor = {Dresher, B. Elan and Friedberg, Nila},
	year = {2006},
	pages = {53--75},
}

@article{glaser_white_2024,
	title = {White {Things}: {Form}, {Formalization}, and the {Use} of},
	volume = {54},
	abstract = {The limited prosodic literacy of revamped formalisms perpetuates the whiteness of lyric reading. By prizing ironic distance and elevating the critic as form's discoverer, the concept of poetic form reinscribes racialized value judgments even where critics hope to valorize nonwhite poetic strategies. Formalism should instead attend to the history that gave poets their sense of form. Nonwhite poets mark how this process of formalization, through which forms become abstracted and bear value, consistently entails racialization. They prompt us, I argue, not to form but to prosodic details whose contingency and phenomenological complexity suspend codes of formalist reading.},
	number = {4},
	journal = {New Literary History},
	author = {Glaser, Ben},
	year = {2024},
	keywords = {Literature},
}

@book{glaser_modernisms_2020,
	address = {Baltimore},
	title = {Modernism's {Metronome} : {Meter} and {Twentieth}-{Century} {Poetics}},
	shorttitle = {Modernism's {Metronome}},
	publisher = {Johns Hopkins University Press},
	author = {Glaser, Ben},
	year = {2020},
	keywords = {American poetry, English language, English poetry, Great Britain, History, History and criticism, Modernism (Literature), Poetics, Rhythm in literature, United States, Versification},
}

@misc{heuser_prosodic_2010,
	title = {Prosodic (software)},
	url = {https://github.com/quadrismegistus/prosodic},
	publisher = {Stanford University},
	author = {Heuser, Ryan and Falk, Joshua and Anttila, Arto},
	year = {2010},
}

@misc{walsh_sonnet_2024,
	title = {Sonnet or {Not}, {Bot}? {Poetry} {Evaluation} for {Large} {Models} and {Datasets}},
	shorttitle = {Sonnet or {Not}, {Bot}?},
	url = {http://arxiv.org/abs/2406.18906},
	doi = {10.48550/arXiv.2406.18906},
	abstract = {Large language models (LLMs) can now generate and recognize poetry. But what do LLMs really know about poetry? We develop a task to evaluate how well LLMs recognize one aspect of English-language poetry--poetic form--which captures many different poetic features, including rhyme scheme, meter, and word or line repetition. By using a benchmark dataset of over 4.1k human expert-annotated poems, we show that state-of-the-art LLMs can successfully identify both common and uncommon fixed poetic forms--such as sonnets, sestinas, and pantoums--with surprisingly high accuracy. However, performance varies significantly by poetic form; the models struggle to identify unfixed poetic forms, especially those based on topic or visual features. We additionally measure how many poems from our benchmark dataset are present in popular pretraining datasets or memorized by GPT-4, finding that pretraining presence and memorization may improve performance on this task, but results are inconclusive. We release a benchmark evaluation dataset with 1.4k public domain poems and form annotations, results of memorization experiments and data audits, and code.},
	urldate = {2024-10-24},
	publisher = {arXiv},
	author = {Walsh, Melanie and Preus, Anna and Antoniak, Maria},
	month = oct,
	year = {2024},
	note = {arXiv:2406.18906},
	keywords = {Computer Science - Computation and Language},
}

@article{da_computational_2019,
	title = {The {Computational} {Case} against {Computational} {Literary} {Studies}},
	volume = {45},
	number = {3},
	journal = {Critical Inquiry},
	author = {Da, Nan Z.},
	month = mar,
	year = {2019},
	pages = {601--639},
}

@article{porter_ai-generated_2024,
	title = {{AI}-generated poetry is indistinguishable from human-written poetry and is rated more favorably},
	volume = {14},
	number = {1},
	journal = {Scientific Reports},
	author = {Porter, Brian and Machery, Edouard},
	month = nov,
	year = {2024},
	pages = {26133},
}

@article{elam_poetry_2023,
	title = {Poetry {Will} {Not} {Optimize}; or, {What} {Is} {Literature} to {AI}?},
	volume = {95},
	issn = {0002-9831, 1527-2117},
	url = {https://read.dukeupress.edu/american-literature/article/95/2/281/344231/Poetry-Will-Not-Optimize-or-What-Is-Literature-to},
	doi = {10.1215/00029831-10575077},
	abstract = {Literature, poetry, and other forms of noncommercial creative expression challenge the techno-instrumentalist approaches to language, the predictive language generation, informing NLP (large natural language processing models) such as GPT-3 or -4 as well as, more generally, generative AI (text to image, video, audio). Claims that AI systems automate and expedite creativity reﬂect industry and research priorities of speed, scale, optimization, and frictionlessness driving much artiﬁcial intelligence design and application. But poetry will not optimize; the creative process cannot be reduced to a prompt. Some have noted that literary creations generated or augmented by artiﬁcial intelligence at best can offer form without meaning; using a GPT creation prompted by Maya Angelou’s poem “Still I Rise” as a case study, this essay argues that NLP’s predictive language generation and what I call algorithmic ahistoricity can also, more disturbingly, render meaning senseless. In doing so, GPT-3’s literary experiments are not “failed” because they do not meet some moving target of a literary standard, nor because of technological insufﬁciency, but because it can make it harder for people to name and navigate their realities. The coda explores an example of AI as literary interlocutor and creative engagement beyond optimization.},
	language = {en},
	number = {2},
	urldate = {2024-11-20},
	journal = {American Literature},
	author = {Elam, Michele},
	month = jun,
	year = {2023},
	pages = {281--303},
}

@misc{walsh_does_2024,
	title = {Does {ChatGPT} {Have} a {Poetic} {Style}?},
	url = {http://arxiv.org/abs/2410.15299},
	abstract = {Generating poetry has become a popular application of LLMs, perhaps especially of OpenAI's widely-used chatbot ChatGPT. What kind of poet is ChatGPT? Does ChatGPT have its own poetic style? Can it successfully produce poems in different styles? To answer these questions, we prompt the GPT-3.5 and GPT-4 models to generate English-language poems in 24 different poetic forms and styles, about 40 different subjects, and in response to 3 different writing prompt templates. We then analyze the resulting 5.7k poems, comparing them to a sample of 3.7k poems from the Poetry Foundation and the Academy of American Poets. We find that the GPT models, especially GPT-4, can successfully produce poems in a range of both common and uncommon English-language forms in superficial yet noteworthy ways, such as by producing poems of appropriate lengths for sonnets (14 lines), villanelles (19 lines), and sestinas (39 lines). But the GPT models also exhibit their own distinct stylistic tendencies, both within and outside of these specific forms. Our results show that GPT poetry is much more constrained and uniform than human poetry, showing a strong penchant for rhyme, quatrains (4-line stanzas), iambic meter, first-person plural perspectives (we, us, our), and specific vocabulary like "heart," "embrace," "echo," and "whisper."},
	urldate = {2024-11-20},
	publisher = {arXiv},
	author = {Walsh, Melanie and Preus, Anna and Gronski, Elizabeth},
	month = oct,
	year = {2024},
	keywords = {Computer Science - Computation and Language},
}

@misc{davis_chatgpts_2024,
	title = {{ChatGPT}’s {Poetry} is {Incompetent} and {Banal}: {A} {Discussion} of ({Porter} and {Machery}, 2024)},
	url = {https://cs.nyu.edu/~davise/papers/GPT-Poetry.pdf},
	author = {Davis, Ernest},
	year = {2024},
}

@article{butterfield_fuzziness_2012,
	title = {Fuzziness and {Perceptions} of {Language} in the {Middle} {Ages}: {Part} 1: {Explosive} {Fuzziness}: {The} {Duel}},
	volume = {18},
	abstract = {Vernacular language use in England throughout the later Middle Ages was a complex negotiation between English and French; that is, between the languages of English and French and the political identities of two peoples engaged in a long war. Clifford Geertz's famous analysis of “blurred genres” is used to think through the fuzzy properties of this period's bilingualism and to argue that to understand the boundaries between English and French as blurred is revealing of the linguistic and social tensions that were the product of conflict between two closely intertwined cultures. This article is the first of a three-part contribution to the Common Knowledge symposium on “blur,” each part corresponding broadly to Geertz's trifold instances of blur as involving “face-to-face interaction” (“life as game”), “collective intensities” (“life as stage”), and “imaginative forms” (“life as text”). This first part takes as its main example a duel described by Jean Froissart in his Chroniques, in which a French knight is punished by his own king, Charles V, for fighting and injuring an English knight on the outskirts of Calais in 1383.},
	number = {2},
	journal = {Common Knowledge},
	author = {Butterfield, Ardis},
	year = {2012},
	pages = {255--266},
}

@article{chakrabarty_help_2022,
	title = {Help me write a poem: {Instruction} {Tuning} as a {Vehicle} for {Collaborative} {Poetry} {Writing}},
	journal = {Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing},
	author = {Chakrabarty, Tuhin and Padmakumar, Vishakh and He, He},
	year = {2022},
	pages = {6848--6863},
}

@article{mccoy_embers_2024,
	title = {Embers of autoregression show how large language models are shaped by the problem they are trained to solve},
	volume = {121},
	abstract = {The widespread adoption of large language models (LLMs) makes it important to recognize their strengths and limitations. We argue that to develop a holistic understanding of these systems, we must consider the problem that they were trained to solve: next-word prediction over Internet text. By recognizing the pressures that this task exerts, we can make predictions about the strategies that LLMs will adopt, allowing us to reason about when they will succeed or fail. Using this approach—which we call the teleological approach—we identify three factors that we hypothesize will influence LLM accuracy: the probability of the task to be performed, the probability of the target output, and the probability of the provided input. To test our predictions, we evaluate five LLMs (GPT-3.5, GPT-4, Claude 3, Llama 3, and Gemini 1.0) on 11 tasks, and we find robust evidence that LLMs are influenced by probability in the hypothesized ways. Many of the experiments reveal surprising failure modes. For instance, GPT-4’s accuracy at decoding a simple cipher is 51\% when the output is a high-probability sentence but only 13\% when it is low-probability, even though this task is a deterministic one for which probability should not matter. These results show that AI practitioners should be careful about using LLMs in low-probability situations. More broadly, we conclude that we should not evaluate LLMs as if they are humans but should instead treat them as a distinct type of system—one that has been shaped by its own particular set of pressures.},
	number = {41},
	journal = {Proceedings of the National Academy of Sciences},
	author = {McCoy, R. Thomas and Yao, Shunyu and Friedman, Dan and Hardy, Mathew D. and Griffiths, Thomas L.},
	month = oct,
	year = {2024},
}
