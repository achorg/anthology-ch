<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>Llamas Don’t Understand Fiction: Application and Evaluation of Large
Language Models for Knowledge Extraction from Short Stories in
English</title>
  <link rel="preconnect" href="https://fonts.googleapis.com">
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
  <link href="https://fonts.googleapis.com/css2?family=Tinos:ital,wght@0,400;0,700;1,400;1,700&display=swap" rel="stylesheet">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/bulma/0.9.4/css/bulma.min.css">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.0/css/all.min.css">
  <link rel="stylesheet" href="../../../css/site.css">

  <!-- citation information -->
  <link rel="canonical" href="https://anthology.ach.org/volumes/vol0003/llamas-don-t-understand-fiction-application-of-for/">
  <meta name="citation_title" content="Llamas Don’t Understand Fiction: Application and Evaluation of Large
Language Models for Knowledge Extraction from Short Stories in
English">
  <meta name="citation_date" content="2025">
  <meta name="citation_public_url" content="https://anthology.ach.org/volumes/vol0003/llamas-don-t-understand-fiction-application-of-for/">
  <meta name="citation_journal_title" content="Anthology of Computers and the Humanities">
  <meta name="citation_issn" content="">
  <meta name="citation_volume" content="3">
  <meta name="citation_firstpage" content="4">
  <meta name="citation_lastpage" content="32">
  <meta name="citation_doi" content="10.63744/iCGYNUN0uUAe">
  <meta name="citation_author" content="Graciotti, Arianna">
  <meta name="citation_author" content="Pannach, Franziska">
  <meta name="citation_author" content="Presutti, Valentina">
  <meta name="citation_author" content="Pianzola, Federico">
  <meta name="citation_editor" content="Arnold, Taylor">
  <meta name="citation_editor" content="Fantoli, Margherita">
  <meta name="citation_editor" content="Ros, and Ruben">
  <meta name="citation_abstract" content="Extracting event knowledge from unstructured text is a well-known
challenge in Natural Language Processing (NLP) and is particularly
difficult when dealing with fiction. Subtext, rather than explicit
information, and figurative style in fictional narratives, complicate
event extraction. Recent advances in Large Language Models (LLMs) have
improved performance across various NLP tasks. However, their
effectiveness in extracting events from fiction remains underexplored.
In this article, we evaluate the performance of open-weights LLMs to
extract character death events from fictional narratives in English.
These events are defined as triples consisting of &lt;em&gt;Victim&lt;/em&gt;,
&lt;em&gt;Perpetrator&lt;/em&gt;, and &lt;em&gt;Mode of Demise&lt;/em&gt;. We cast Knowledge
Extraction (KE) as a zero-shot task and evaluate our approach on a
manually annotated benchmark of fanfiction stories. Our results show
that LLMs struggle with KE from fiction, with a maximum F1-score of
&lt;span class=&#34;math inline&#34;&gt;0.45&lt;/span&gt; across the elements constituting
the triples and, at most, &lt;span class=&#34;math inline&#34;&gt;25%&lt;/span&gt; of death
events correctly extracted. A detailed error analysis reveals that most
errors stem from missed death events and from direct presentation modes,
such as direct speech, which significantly impair extraction
performance. Moreover, KE accuracy declines as the story length
increases, while LLMs’ background knowledge leakage contributes to false
positives. These findings provide domain-specific insights into the
challenges of KE in fiction.">
  <meta name="citation_language" content="en">
  <meta name="citation_keywords" content="Event Extraction; Fiction; Human-Centered Evaluation; LLMs; Zero/Few-Shot Extraction">
  <meta name="citation_fulltext_html_url" content="https://anthology.ach.org/volumes/vol0003/llamas-don-t-understand-fiction-application-of-for/">
  <meta name="citation_pdf_url" content="https://anthology.ach.org/volumes/vol0003/llamas-don-t-understand-fiction-application-of-for/10.63744@iCGYNUN0uUAe.pdf">

  <!-- Lightbox CSS -->
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/lightbox2/2.11.4/css/lightbox.min.css" />

  <!-- Pandoc syntax highlighting CSS -->
  <link rel="stylesheet" href="../../../css/syntax-highlighting.css" />
  <link rel="stylesheet" href="../../../css/article.css" />


</head>
<body>
  <!-- Navigation Bar -->
  <nav class="navbar" role="navigation" aria-label="main navigation">
    <div class="navbar-brand">
      <a class="navbar-item" href="https://ach.org">
        <img src="../../../logo/logo.png" alt="ACH Logo">
      </a>

      <a role="button" class="navbar-burger" aria-label="menu" aria-expanded="false" data-target="navbarBasicExample">
        <span aria-hidden="true"></span>
        <span aria-hidden="true"></span>
        <span aria-hidden="true"></span>
      </a>
    </div>

    <div class="navbar-menu" id="navbarMain">
      <div class="navbar-start">
      </div>
      <div class="navbar-end">
        <a class="navbar-item" href="https://anthology.ach.org/">
          <b>Home</b>
        </a>
        <a class="navbar-item" href="https://anthology.ach.org/volumes/">
          <b>Volumes</b>
        </a>
        <a class="navbar-item" href="https://anthology.ach.org/about">
          <b>About</b>
        </a>
        <span style="width: 25px"></span>
      </div>
    </div>
  </nav>

  <!-- Hero Section -->
  <section class="hero">
    <div class="hero-body">
      <div class="container">
        <p class="subtitle is-6 has-text-grey">Anthology of Computers and the Humanities · <a href="..">Volume 3</a></p>
        <h1 class="title paper-title">Llamas Don’t Understand Fiction: Application and Evaluation of Large
Language Models for Knowledge Extraction from Short Stories in
English</h1>

        <div class="is-size-5 pl-7 has-text-centered">
          <a href="https://creativecommons.org/licenses/by/4.0/?ref=chooser-v1" target="_blank" rel="license noopener noreferrer" style="display:inline-block;"><img style="height:25px!important;margin-left:3px;vertical-align:text-bottom;" src="../../../logo/cc-by.png"></a>
        </div>
      </div>

    </div>
  </section>

  <!-- Main Content -->
  <section class="section">
    <div class="container">

      <div class="paper-meta">
        <div class="authors-container">
          <div class="authors">
            <section class="authors-block">
              <p class="authors">
                  <span class="author">
                    Arianna Graciotti<sup>1,2</sup><a class="orcid-link" href="https://orcid.org/0009-0004-7918-809X" target="_blank" rel="noopener">
                        <img class="orcid" src="../../../logo/orcid.png" alt="ORCID">
                      </a>
                  </span>,
                  <span class="author">
                    Franziska Pannach<sup>1</sup><a class="orcid-link" href="https://orcid.org/0000-0003-4216-8410" target="_blank" rel="noopener">
                        <img class="orcid" src="../../../logo/orcid.png" alt="ORCID">
                      </a>
                  </span>,
                  <span class="author">
                    Valentina Presutti<sup>1</sup><a class="orcid-link" href="https://orcid.org/0000-0002-9380-5160" target="_blank" rel="noopener">
                        <img class="orcid" src="../../../logo/orcid.png" alt="ORCID">
                      </a>
                  </span> and
                  <span class="author">
                    Federico Pianzola<sup>1</sup><a class="orcid-link" href="https://orcid.org/0000-0002-4545-1548" target="_blank" rel="noopener">
                        <img class="orcid" src="../../../logo/orcid.png" alt="ORCID">
                      </a>
                  </span>
              </p>

              <ul class="affiliations">
                  <li><sup>1</sup> Centre for Language and Cognition, University of Groningen,
Groningen, Netherlands</li>
                  <li><sup>2</sup> Department of Languages, Literatures and Modern Cultures, University
of Bologna, Bologna, Italy</li>
              </ul>
            </section>

          </div>
        </div>
      </div>


      <!-- Download Buttons -->
      <div class="buttons-container">
        <a href="10.63744@iCGYNUN0uUAe.pdf" class="button is-primary" target="_blank">
          <span class="icon">
            <i class="fas fa-file-pdf"></i>
          </span>
          <span>Download PDF</span>
        </a>
        <a href="10.63744@iCGYNUN0uUAe.bib" class="button is-info" target="_blank">
          <span class="icon">
            <i class="fas fa-file-code"></i>
          </span>
          <span>Download Citation</span>
        </a>
        
      </div>

      <!-- DOI -->
      <div class="doi-box">
        <p class="is-size-6">
          <b>Permanent Link:</b> <a class="doi-link" href="https://doi.org/10.63744/iCGYNUN0uUAe" target="_blank">https://doi.org/10.63744/iCGYNUN0uUAe</a>
        </p>
        <p class="is-size-6">
          <b>Published:</b> 21 November 2025
        </p>
        <p class="is-size-6">
          <b>Keywords:</b> Event Extraction, Fiction, Human-Centered Evaluation, LLMs, Zero/Few-Shot Extraction
        </p>
      </div>

      <!-- Abstract -->
      <div class="content">
         <div class="abs"><span>Abstract</span><p>Extracting event knowledge from unstructured text is a well-known challenge in Natural Language Processing (NLP) and is particularly difficult when dealing with fiction. Subtext, rather than explicit information, and figurative style in fictional narratives, complicate event extraction. Recent advances in Large Language Models (LLMs) have improved performance across various NLP tasks. However, their effectiveness in extracting events from fiction remains underexplored. In this article, we evaluate the performance of open-weights LLMs to extract character death events from fictional narratives in English. These events are defined as triples consisting of <em>Victim</em>, <em>Perpetrator</em>, and <em>Mode of Demise</em>. We cast Knowledge Extraction (KE) as a zero-shot task and evaluate our approach on a manually annotated benchmark of fanfiction stories. Our results show that LLMs struggle with KE from fiction, with a maximum F1-score of <span class="math inline">0.45</span> across the elements constituting the triples and, at most, <span class="math inline">25%</span> of death events correctly extracted. A detailed error analysis reveals that most errors stem from missed death events and from direct presentation modes, such as direct speech, which significantly impair extraction performance. Moreover, KE accuracy declines as the story length increases, while LLMs’ background knowledge leakage contributes to false positives. These findings provide domain-specific insights into the challenges of KE in fiction.</p></div>


      </div>

    </div>
  </section>

  <!-- Footer -->
  <footer class="footer">
    <div class="content has-text-centered">
      <p>
        <strong>Anthology of Computers and the Humanities</strong> · Association for Computers and the Humanities
      </p>
      <p class="is-size-7">
        Paper © 2025 the authors. All other content © 2025 ACH.
      </p>
    </div>
  </footer>


  <!-- Lightbox JavaScript -->
  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/lightbox2/2.11.4/js/lightbox.min.js"></script>

  <!-- Prism.js for syntax highlighting -->
  <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.30.0/prism.min.js"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.30.0/components/prism-python.min.js"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.30.0/components/prism-bash.min.js"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.30.0/components/prism-xml.min.js"></script>

  <!-- Custom JavaScript -->
  <script src="../../../js/navbar.js"></script>
  <script src="../../../js/lightbox-config.js"></script>
  <script src="../../../js/code-copy.js"></script>

</body>
</html>