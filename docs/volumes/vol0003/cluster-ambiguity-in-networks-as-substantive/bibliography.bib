@article{Good_De_Montjoye_Clauset_2010, title={Performance of modularity maximization in practical contexts}, volume={81}, ISSN={15393755}, DOI={10.1103/PhysRevE.81.046106}, abstractNote={Although widely used in practice, the behavior and accuracy of the popular module identification technique called modularity maximization is not well understood in practical contexts. Here, we present a broad characterization of its performance in such situations. First, we revisit and clarify the resolution limit phenomenon for modularity maximization. Second, we show that the modularity function Q exhibits extreme degeneracies: it typically admits an exponential number of distinct high-scoring solutions and typically lacks a clear global maximum. Third, we derive the limiting behavior of the maximum modularity Qmax for one model of infinitely modular networks, showing that it depends strongly both on the size of the network and on the number of modules it contains. Finally, using three real-world metabolic networks as examples, we show that the degenerate solutions can fundamentally disagree on many, but not all, partition properties such as the composition of the largest modules and the distribution of module sizes. These results imply that the output of any modularity maximization procedure should be interpreted cautiously in scientific contexts. They also explain why many heuristics are often successful at finding high-scoring partitions in practice and why different heuristics can disagree on the modular structure of the same network. We conclude by discussing avenues for mitigating some of these behaviors, such as combining information from many degenerate solutions or using generative models. © 2010 The American Physical Society.}, note={arXiv: 0910.0165}, number={4}, journal={Physical Review E - Statistical, Nonlinear, and Soft Matter Physics}, publisher={American Physical Society}, author={Good, Benjamin H. and De Montjoye, Yves Alexandre and Clauset, Aaron}, year={2010}, month=apr, pages={046106} }

@article{Peixoto_2021, title={Revealing Consensus and Dissensus between Network Partitions}, volume={11}, DOI={10.1103/PhysRevX.11.021003}, abstractNote={Community detection methods attempt to divide a network into groups of nodes that share similar properties, thus revealing its large-scale structure. A major challenge when employing such methods is that they are often degenerate, typically yielding a complex landscape of competing answers. As an attempt to extract understanding from a population of alternative solutions, many methods exist to establish a consensus among them in the form of a single partition “point estimate” that summarizes the whole distribution. Here, we show that it is, in general, not possible to obtain a consistent answer from such point estimates when the underlying distribution is too heterogeneous. As an alternative, we provide a comprehensive set of methods designed to characterize and summarize complex populations of partitions in a manner that captures not only the existing consensus but also the dissensus between elements of the population. Our approach is able to model mixed populations of partitions, where multiple consensuses can coexist, representing different competing hypotheses for the network structure. We also show how our methods can be used to compare pairs of partitions, how they can be generalized to hierarchical divisions, and how they can be used to perform statistical model selection between competing hypotheses.}, number={2}, journal={Physical Review X}, publisher={American Physical Society}, author={Peixoto, Tiago P.}, year={2021}, month=apr, pages={021003} }

@article{Calatayud_Bernardo-Madrid_Neuman_Rojas_Rosvall_2019, title={Exploring the solution landscape enables more reliable network community detection}, volume={100}, ISSN={24700053}, DOI={10.1103/PhysRevE.100.052308}, abstractNote={To understand how a complex system is organized and functions, researchers often identify communities in the system’s network of interactions. Because it is practically impossible to explore all solutions to guarantee the best one, many community-detection algorithms rely on multiple stochastic searches. But for a given combination of network and stochastic algorithms, how many searches are sufficient to find a solution that is good enough? The standard approach is to pick a reasonably large number of searches and select the network partition with the highest quality or derive a consensus solution based on all network partitions. However, if different partitions have similar qualities such that the solution landscape is degenerate, the single best partition may miss relevant information, and a consensus solution may blur complementary communities. Here we address this degeneracy problem with coarse-grained descriptions of the solution landscape. We cluster network partitions based on their similarity and suggest an approach to determine the minimum number of searches required to describe the solution landscape adequately. To make good use of all partitions, we also propose different ways to explore the solution landscape, including a significance clustering procedure. We test these approaches on synthetic networks and a real-world network using two contrasting community-detection algorithms: The algorithm that can identify more general structures requires more searches, and networks with clearer community structures require fewer searches. We also find that exploring the coarse-grained solution landscape can reveal complementary solutions and enable more reliable community detection.}, note={arXiv: 1905.11230 publisher: American Physical Society}, number={5}, journal={Physical Review E}, author={Calatayud, Joaquín and Bernardo-Madrid, Rubén and Neuman, Magnus and Rojas, Alexis and Rosvall, Martin}, year={2019}, month=nov, pages={052308} }

@article{Drucker_2018, title={Non-representational approaches to modeling interpretation in a graphical environment}, volume={33}, ISSN={2055-7671}, DOI={10.1093/llc/fqx034}, abstractNote={This article presents an epistemological rationale, intellectual justification, and design outline for a non-representational approach to modeling interpretation in a graphical environment. It begins with a brief critical discussion of the representational approaches that are the common form of information visualizations and suggests that the less familiar non-representational approach could be used to augment these existing visualizations by supporting interpretative work that is closer to the practice of humanistic hermeneutic traditions. Representational display, based on large-scale processing, surrogates, and conventional visualizations, and non-representational modeling at the level of the individual interpretative act operate at very different scales to support intellectual work. In a representational approach, data precede display. Display is a surrogate produced according to automated protocols and algorithms. These cannot be altered or intervened except through rewriting their code, and the display, though interpretative and subject to interpretation, cannot be used as a means by which interpretation is actually modeled. While all visualizations express a model, they do not all provide a modeling environment. In the non-representational approach proposed here, graphical input serves as a primary means of interpretative work. More significantly, a graphical environment that supports direct modeling of interpretation allows traditional humanistic approaches, close reading, and marking of texts, documents, artifacts, or images, to be integrated with computationally produced visualizations. This research was developed as part of the 3DH (three-dimensional/digital humanities) project hosted at the University of Hamburg, between April and June 2016.}, number={2}, journal={Digital Scholarship in the Humanities}, author={Drucker, Johanna}, year={2018}, month=jun, pages={248–263} }

@article{Windhager_Salisu_Mayr_2019, title={Exhibiting Uncertainty: Visualizing Data Quality Indicators for Cultural Collections}, volume={6}, rights={http://creativecommons.org/licenses/by/3.0/}, ISSN={2227-9709}, DOI={10.3390/informatics6030029}, abstractNote={Uncertainty is a standard condition under which large parts of art-historical and curatorial knowledge creation and communication are operating. In contrast to standard levels of data quality in non-historical research domains, historical object and knowledge collections contain substantial amounts of uncertain, ambiguous, contested, or plainly missing data. Visualization approaches and interfaces to cultural collections have started to represent data quality and uncertainty metrics, yet all existing work is limited to representations for isolated metadata dimensions only. With this article, we advocate for a more systematic, synoptic and self-conscious approach to uncertainty visualization for cultural collections. We introduce omnipresent types of data uncertainty and discuss reasons for their frequent omission by interfaces for galleries, libraries, archives and museums. On this basis we argue for a coordinated counter strategy for uncertainty visualization in this field, which will also raise the efforts going into complex interface design and conceptualization. Building on the PolyCube framework for collection visualization, we showcase how multiple uncertainty representation techniques can be assessed and coordinated in a multi-perspective environment. As for an outlook, we reflect on both the strengths and limitations of making the actual wealth of data quality questions transparent with regard to different target and user groups.}, number={33}, journal={Informatics}, publisher={Multidisciplinary Digital Publishing Institute}, author={Windhager, Florian and Salisu, Saminu and Mayr, Eva}, year={2019}, month=sep, pages={29}, language={en} }

@inproceedings{Therón_Wandl-vogt_2018, address={New York, NY, USA}, series={TEEM’18}, title={Uncertainty in Digital Humanities track summary}, ISBN={978-1-4503-6518-5}, url={https://dl.acm.org/doi/10.1145/3284179.3284317}, DOI={10.1145/3284179.3284317}, abstractNote={Digital humanities methods and techniques have been applied to a wide spectrum of disciplines with results there were not attainable otherwise. However, uncertainty is present in any DH endeavour, in various types and degrees, due to the very nature of both humanist research and the intervention of computers to enable such kind of research methodologies. On the one hand, information sources need to be converted into digital form and, on the other hand, the resulting digital objects are processed to obtain summaries, geographic and temporal distributions, networks, patterns, etc., that are presented to and interpreted by the researchers or users of the DH projects. From the digitalization to the interpretation, both the computational and cognitive steps involved are subject to uncertainty. The track “Uncertainty in Digital Humanities” of the Sixth International Conference on Technological Ecosystems for Enhancing Multiculturality (TEEM 2018), tries to bring together researchers in Digital Humanities and reflect on the opportunities and challenges related to the way in which uncertainty can be better understood and pave the way towards appropriate methods and tools of dealing with uncertainty that improve the support to humanists when generating new knowledge.}, booktitle={Proceedings of the Sixth International Conference on Technological Ecosystems for Enhancing Multiculturality}, publisher={Association for Computing Machinery}, author={Therón, Roberto and Wandl-vogt, Eveline}, year={2018}, month=oct, pages={815–818}, collection={TEEM’18} }

@book{Levontin_et_al_2020, title={Visualising Uncertainty: A short introduction}, ISBN={978-1-912802-05-0}, abstractNote={The basis of this short introduction is a review of the literature on communicating uncertainty, with a particular focus on visualising uncertainty. From our review, one thing emerges very clearly: there is no ‘optimal’ format or framework for visualising uncertainty. Instead, the implementation of visualisation techniques must be studied on a case-by-case basis, and supported by empirical testing.}, author={Levontin, Polina and Walton, Jo and Aufegger, Lisa and Barons, Martine and Barons, Edward and French, Simon and Houssineau, Jeremie and Kleineberg, Jana and Mcbride, Marissa and Smith, Jim}, year={2020}, month=jan }

@article{Guo_Huang_Laidlaw_2015, title={Representing Uncertainty in Graph Edges: An Evaluation of Paired Visual Variables}, volume={21}, ISSN={1941-0506}, DOI={10.1109/TVCG.2015.2424872}, abstractNote={When visualizing data with uncertainty, a common approach is to treat uncertainty as an additional dimension and encode it using a visual variable. The effectiveness of this approach depends on how the visual variables chosen for representing uncertainty and other attributes interact to influence the user’s perception of each variable. We report a user study on the perception of graph edge attributes when uncertainty associated with each edge and the main edge attribute are visualized simultaneously using two separate visual variables. The study covers four visual variables that are commonly used for visualizing uncertainty on line graphical primitives: lightness, grain, fuzziness, and transparency. We select width, hue, and saturation for visualizing the main edge attribute and hypothesize that we can observe interference between the visual variable chosen to encode the main edge attribute and that to encode uncertainty, as suggested by the concept of dimensional integrality. Grouping the seven visual variables as color-based, focus-based, or geometry-based, we further hypothesize that the degree of interference is affected by the groups to which the two visual variables belong. We consider two further factors in the study: discriminability level for each visual variable as a factor intrinsic to the visual variables and graph-task type (visual search versus comparison) as a factor extrinsic to the visual variables. Our results show that the effectiveness of a visual variable in depicting uncertainty is strongly mediated by all the factors examined here. Focus-based visual variables (fuzziness, grain, and transparency) are robust to the choice of visual variables for encoding the main edge attribute, though fuzziness has stronger negative impact on the perception of width and transparency has stronger negative impact on the perception of hue than the other uncertainty visual variables. We found that interference between hue and lightness is much greater than that between saturation and lightness, though all three are color-based visual variables. We also found a compound relationship between discriminability level and the degree of dimensional integrality. We discuss the generalizability and limitation of the results and conclude with design considerations for visualizing graph uncertainty derived from these results, including recommended choices of visual variables when the relative importance of data attributes and graph tasks is known.}, number={10}, journal={IEEE Transactions on Visualization and Computer Graphics}, author={Guo, Hua and Huang, Jeff and Laidlaw, David H.}, year={2015}, month=oct, pages={1173–1186} }

@article{Conroy_Gillmann_et_al_2024, title={Uncertainty in humanities network visualization}, volume={8}, ISSN={2297-900X}, url={https://www.frontiersin.org/journals/communication/articles/10.3389/fcomm.2023.1305137/full}, DOI={10.3389/fcomm.2023.1305137}, abstractNote={Network visualization is one of the most widely used tools in digital humanities research. Networks have been used to study the structure of social groups, the circulation of texts, the relation of words within a text to one another, and countless other structures that are employed in digital humanities research. The idea of uncertain or “fuzzy” data is also a core notion in digital humanities research. Yet network visualizations in digital humanities do not always prominently represent uncertainty. In this article, we review some of the principles for visualizing uncertainty of different kinds and consider how these visualizations could be used in digital humanities research. We focus on elements that can be integrated into the network diagram, rather than the displayed data, or accompanying diagrams. We show that, rather than being unique to the digital humanities, uncertainty in this realm is in many ways analogous to the concept and uses of uncertainty in other disciplines; we also show how techniques for visualizing uncertainty in fields like climate science and bioinformatics could be used to represent more prominently some of the types of uncertainty that we find in humanities data.}, journal={Frontiers in Communication}, publisher={Frontiers}, author={Conroy, Melanie and Gillmann, Christina and Harvey, Francis and Mchedlidze, Tamara and Fabrikant, Sara Irina and Windhager, Florian and Scheuermann, Gerik and Tangherlini, Timothy R. and Warren, Christopher N. and Weingart, Scott B. and Rehbein, Malte and Börner, Katy and Elo, Kimmo and Jänicke, Stefan and Kerren, Andreas and Nöllenburg, Martin and Dwyer, Tim and Eide, Øyvind and Kobourov, Stephen and Betz, Gregor}, year={2024}, month=jan, language={English} }

@book{Drucker_2011, title={Humanities Approaches to Graphical Display}, abstractNote={As digital visualization tools have become more ubiquitous, humanists have adopted many applications such as GIS mapping, graphs, and charts for statistical display that were developed in other disciplines. But, I will argue, such graphical tools are a kind of intellectual Trojan horse, a vehicle through which assumptions about what constitutes information swarm with potent force. These assumptions are cloaked in a rhetoric taken wholesale from the techniques of the empirical sciences that conceals their epistemological biases under a guise of familiarity. So naturalized are the google maps and bar charts generated from spread sheets that they pass as unquestioned representations of “what is.” This is the hallmark of realist models of knowledge and needs to be subjected to a radical critique to return the humanistic tenets of constructed-ness and interpretation to the fore. Realist approaches depend above all upon an idea that phenomena are observer-independent and can be characterized as data. Data pass themselves off as mere descriptions of a priori conditions. Rendering observation (the act of creating a statistical, empirical, or subjective account or image) as if it were the same as the phenomena observed collapses the critical distance between the phenomenal world and its interpretation, undoing the basis of interpretation on which humanistic knowledge production is based. We know this. But we seem ready and eager to suspend critical judgment in a rush to visualization. At the very least, humanists beginning to play at the intersection of statistics and graphics ought to take a detour through the substantial discussions of the sociology of knowledge and its developed critique of realist models of data gathering. 1 At best, we need to take on the challenge of developing graphical expressions rooted in and appropriate to interpretative activity. Because realist approaches to visualization assume transparency and equivalence, as if the phenomenal world were self-evident and the apprehension of it a mere mechanical task, they are fundamentally at odds with approaches to humanities scholarship premised on constructivist principles. I would argue that even for realist models, those that presume an observer-independent reality available to description, the methods of presenting ambiguity and uncertainty in more nuanced terms would be useful. Some significant progress is being made in visualizing uncertainty in data models for GIS, decision-making, archaeological research and other domains. 2 But an important distinction needs to be clear from the outset: the task of representing ambiguity and uncertainty has to be distinguished from a second task-that of using ambiguity and uncertainty as the basis on which a representation is constructed. This is the difference between putting many kinds of points on a map to show degrees of certainty by shades of color, degrees of crispness, transparency etc., and creating a map whose basic coordinate grid is constructed as an effect of these ambiguities. In the first instance, we have a standard map with a nuanced symbol set. In the second, we create a non-standard map that expresses the constructed-ness of space. Both rely on rethinking our approach to visualization and the assumptions that underpin it. To overturn the assumptions that structure conventions acquired from other domains requires that we reexamine the intellectual foundations of digital humanities, putting techniques of graphical display on a foundation that is humanistic at its base. This}, journal={undefined}, author={Drucker, Johanna}, year={2011} }

@article{Blondel_Guillaume_Lambiotte_Lefebvre_2008, title={Fast unfolding of communities in large networks}, volume={2008}, ISSN={17425468}, DOI={10.1088/1742-5468/2008/10/P10008}, abstractNote={We propose a simple method to extract the community structure of large networks. Our method is a heuristic method that is based on modularity optimization. It is shown to outperform all other known community detection methods in terms of computation time. Moreover, the quality of the communities detected is very good, as measured by the so-called modularity. This is shown first by identifying language communities in a Belgian mobile phone network of 2 million customers and by analysing a web graph of 118 million nodes and more than one billion links. The accuracy of our algorithm is also verified on ad hoc modular networks. © 2008 IOP Publishing Ltd.}, note={arXiv: 0803.0476}, number={10}, journal={Journal of Statistical Mechanics: Theory and Experiment}, author={Blondel, Vincent D. and Guillaume, Jean-Loup and Lambiotte, Renaud and Lefebvre, Etienne}, year={2008} }

@article{Newman_2006, title={Modularity and community structure in networks}, volume={103}, ISSN={0027-8424}, DOI={10.1073/pnas.0601602103}, abstractNote={Many networks of interest in the sciences, including social networks, computer networks, and metabolic and regulatory networks, are found to divide naturally into communities or modules. The problem of detecting and characterizing this community structure is one of the outstanding issues in the study of networked systems. One highly effective approach is the optimization of the quality function known as “modularity” over the possible divisions of a network. Here I show that the modularity can be expressed in terms of the eigenvectors of a characteristic matrix for the network, which I call the modularity matrix, and that this expression leads to a spectral algorithm for community detection that returns results of demonstrably higher quality than competing methods in shorter running times. I illustrate the method with applications to several published network data sets.}, note={arXiv: physics/0602124 Citation Key: Newman2006 ISBN: 0027-8424 (Print)r0027-8424 (Linking)}, number={23}, journal={Proceedings of the National Academy of …}, author={Newman, M. E. J.}, year={2006}, pages={8577–8582} }

@article{Lambiotte_Delvenne_Barahona_2014, title={Laplacian Dynamics and Multiscale Modular Structure in Networks}, volume={1}, ISSN={2327-4697}, DOI={10.1109/TNSE.2015.2391998}, abstractNote={Most methods proposed to uncover communities in complex networks rely on their structural properties. Here we introduce the stability of a network partition, a measure of its quality defined in terms of the statistical properties of a dynamical process taking place on the graph. The time-scale of the process acts as an intrinsic parameter that uncovers community structures at different resolutions. The stability extends and unifies standard notions for community detection: modularity and spectral partitioning can be seen as limiting cases of our dynamic measure. Similarly, recently proposed multi-resolution methods correspond to linearisations of the stability at short times. The connection between community detection and Laplacian dynamics enables us to establish dynamically motivated stability measures linked to distinct null models. We apply our method to find multi-scale partitions for different networks and show that the stability can be computed efficiently for large networks with extended versions of current algorithms.}, note={arXiv:0812.1770 [physics]}, number={2}, journal={IEEE Transactions on Network Science and Engineering}, author={Lambiotte, R. and Delvenne, J.-C. and Barahona, M.}, year={2014}, month=jul, pages={76–90} }

@inproceedings{Bastian_Heymann_Jacomy_2009, title={Gephi: An Open Source Software for Exploring and Manipulating Networks}, rights={Creative Commons Attribution 4.0 International License}, ISBN={978-1-57735-421-5}, url={http://www.aaai.org/ocs/index.php/ICWSM/09/paper/viewFile/154/1009/}, abstractNote={Gephi is an open source software for graph and network analysis. It uses a 3D render engine to display large networks in real-time and to speed up the exploration. A flexible and multi-task architecture brings new possibilities to work with complex data sets and produce valuable visual results.¬† We present several key features of Gephi in the context of interactive exploration and interpretation of networks. It provides easy and broad access to network data and allows for spatializing, filtering, navigating, manipulating and clustering. Finally, by presenting dynamic features of Gephi, we highlight key aspects of dynamic network visualization.}, note={Citation Key: Bastian2009 ISSN: 14753898}, booktitle={Third International ICWSM Conference}, author={Bastian, Mathieu and Heymann, Sebastien and Jacomy, Mathieu}, year={2009}, pages={361–362} }

@article{Venturini_Jacomy_Jensen_2021, title={What do we see when we look at networks: Visual network analysis, relational ambiguity, and force-directed layouts}, volume={8}, ISSN={2053-9517}, DOI={10.1177/20539517211018488}, abstractNote={It is increasingly common in natural and social sciences to rely on network visualizations to explore relational datasets and illustrate findings. Such practices have been around long enough to prove that scholars find it useful to project networks in a two-dimensional space and to use their visual qualities as proxies for their topological features. Yet these practices remain based on intuition, and the foundations and limits of this type of exploration are still implicit. To fill this lack of formalization, this paper offers explicit documentation for the kind of visual network analysis encouraged by force-directed layouts. Using the example of a network of Jazz performers, band and record labels extracted from Wikipedia, the paper provides guidelines on how to make networks readable and how to interpret their visual features. It discusses how the inherent ambiguity of network visualizations can be exploited for exploratory data analysis. Acknowledging that vagueness is a feature of many relational datasets in the humanities and social sciences, the paper contends that visual ambiguity, if properly interpreted, can be an asset for the analysis. Finally, we propose two attempts to distinguish the ambiguity inherited from the represented phenomenon from the distortions coming from fitting a multidimensional object in a two-dimensional space. We discuss why these attempts are only partially successful, and we propose further steps towards a metric of spatialization quality.}, number={1}, journal={Big Data \& Society}, publisher={SAGE Publications Ltd}, author={Venturini, Tommaso and Jacomy, Mathieu and Jensen, Pablo}, year={2021}, month=jan, pages={20539517211018488}, language={en} }

@article{Traag_Waltman_Van_Eck_2019, title={From Louvain to Leiden: guaranteeing well-connected communities}, volume={9}, DOI={10.1038/s41598-019-41695-z}, abstractNote={Community detection is often used to understand the structure of large and complex networks. One of the most popular algorithms for uncovering community structure is the so-called Louvain algorithm. We show that this algorithm has a major defect that largely went unnoticed until now: the Louvain algorithm may yield arbitrarily badly connected communities. In the worst case, communities may even be disconnected, especially when running the algorithm iteratively. In our experimental analysis, we observe that up to 25% of the communities are badly connected and up to 16% are disconnected. To address this problem, we introduce the Leiden algorithm. We prove that the Leiden algorithm yields communities that are guaranteed to be connected. In addition, we prove that, when the Leiden algorithm is applied iteratively, it converges to a partition in which all subsets of all communities are locally optimally assigned. Furthermore, by relying on a fast local move approach, the Leiden algorithm runs faster than the Louvain algorithm. We demonstrate the performance of the Leiden algorithm for several benchmark and real-world networks. We find that the Leiden algorithm is faster than the Louvain algorithm and uncovers better partitions, in addition to providing explicit guarantees.}, journal={Scientific Reports}, author={Traag, V. A. and Waltman, L. and Van Eck, N. J.}, year={2019}, month=mar, pages={e5233}, language={en} }

@article{Zhang_Peixoto_2020, title={Statistical inference of assortative community structures}, volume={2}, DOI={10.1103/PhysRevResearch.2.043271}, abstractNote={We develop a principled methodology to infer assortative communities in networks based on a nonparametric Bayesian formulation of the planted partition model. We show that this approach succeeds in finding statistically significant assortative modules in networks, unlike alternatives such as modularity maximization, which systematically overfits both in artificial as well as in empirical examples. In addition, we show that our method is not subject to an appreciable resolution limit, and can uncover an arbitrarily large number of communities, as long as there is statistical evidence for them. Our formulation is amenable to model selection procedures, which allow us to compare it to more general approaches based on the stochastic block model, and in this way reveal whether assortativity is in fact the dominating large-scale mixing pattern. We perform this comparison with several empirical networks and identify numerous cases where the network’s assortativity is exaggerated by traditional community detection methods, and we show how a more faithful degree of assortativity can be identified.}, number={4}, journal={Physical Review Research}, publisher={American Physical Society}, author={Zhang, Lizhi and Peixoto, Tiago P.}, year={2020}, month=nov, pages={043271} }

@inproceedings{Adamic_Glance_2005, title={The political blogosphere and the 2004 US election: divided they blog}, ISBN={1-59593-215-1}, url={http://www.cyberjournalist.net/news/001461.php}, abstractNote={In this paper, we study the linking patterns and discussion topics of political bloggers. Our aim is to measure the degree of interaction between liberal and conservative blogs, and to uncover any differences in the structure of the two communities. Specifically, we analyze the posts of 40 “A-list” blogs over the period of two months preceding the U.S. Presidential Election of 2004, to study how often they referred to one another and to quantify the overlap in the topics they discussed, both within the liberal and conservative communities, and also across communities. We also study a single day snapshot of over 1,000 political blogs. This snapshot captures blogrolls (the list of links to other blogs frequently found in sidebars), and presents a more static picture of a broader blogosphere. Most significantly, we find differences in the behavior of liberal and conservative blogs, with conservative blogs linking to each other more frequently and in a denser pattern.}, booktitle={Proceedings of the 3rd international workshop on Link discovery}, publisher={ACM}, author={Adamic, Lada A and Glance, Natalie}, year={2005}, pages={36–43} }

@article{Jacomy_et_al_2014, title={ForceAtlas2, a continuous graph layout algorithm for handy network visualization designed for the Gephi software}, volume={9}, rights={Creative Commons Attribution 4.0 International License}, ISSN={19326203}, DOI={10.1371/journal.pone.0098679}, abstractNote={Gephi is a network visualization software used in various disciplines (social network analysis, biology, genomics...). One of its key features is the ability to display the spatialization process, aiming at transforming the network into a map, and ForceAtlas2 is its default layout algorithm. The latter is developed by the Gephi team as an all-around solution to Gephi users’ typical networks (scale-free, 10 to 10,000 nodes). We present here for the first time its functioning and settings. ForceAtlas2 is a force-directed layout close to other algorithms used for network spatialization. We do not claim a theoretical advance but an attempt to integrate different techniques such as the Barnes Hut simulation, degree-dependent repulsive force, and local and global adaptive temperatures. It is designed for the Gephi user experience (it is a continuous algorithm), and we explain which constraints it implies. The algorithm benefits from much feedback and is developed in order to provide many possibilities through its settings. We lay out its complete functioning for the users who need a precise understanding of its behaviour, from the formulas to graphic illustration of the result. We propose a benchmark for our compromise between performance and quality. We also explain why we integrated its various features and discuss our design choices.}, note={Citation Key: Jacomy2014 ISBN: 10.1371/journal.pone.0098679}, number={6}, journal={PLoS ONE}, author={Jacomy, Mathieu and Venturini, Tommaso and Heymann, Sebastien and Bastian, Mathieu}, year={2014}, pages={1–18} }

@article{Watts_Strogatz_1998, title={Collective dynamics of ‘small-world’ networks}, volume={393}, rights={1998 Macmillan Magazines Ltd.}, ISSN={1476-4687}, DOI={10.1038/30918}, abstractNote={Networks of coupled dynamical systems have been used to model biological oscillators1,2,3,4, Josephson junction arrays5,6, excitable media7, neural networks8,9,10, spatial games11, genetic control networks12 and many other self-organizing systems. Ordinarily, the connection topology is assumed to be either completely regular or completely random. But many biological, technological and social networks lie somewhere between these two extremes. Here we explore simple models of networks that can be tuned through this middle ground: regular networks ‘rewired’ to introduce increasing amounts of disorder. We find that these systems can be highly clustered, like regular lattices, yet have small characteristic path lengths, like random graphs. We call them ‘small-world’ networks, by analogy with the small-world phenomenon13,14 (popularly known as six degrees of separation15). The neural network of the worm Caenorhabditis elegans, the power grid of the western United States, and the collaboration graph of film actors are shown to be small-world networks. Models of dynamical systems with small-world coupling display enhanced signal-propagation speed, computational power, and synchronizability. In particular, infectious diseases spread more easily in small-world networks than in regular lattices.}, number={6684}, journal={Nature}, publisher={Nature Publishing Group}, author={Watts, Duncan J. and Strogatz, Steven H.}, year={1998}, month=jun, pages={440–442}, language={en} }

@article{Wang_Shen_Archambault_Zhou_Zhu_Yang_Qu_2016, title={AmbiguityVis: Visualization of Ambiguity in Graph Layouts}, volume={22}, ISSN={10772626}, DOI={10.1109/TVCG.2015.2467691}, abstractNote={Node-link diagrams provide an intuitive way to explore networks and have inspired a large number of automated graph layout strategies that optimize aesthetic criteria. However, any particular drawing approach cannot fully satisfy all these criteria simultaneously, producing drawings with visual ambiguities that can impede the understanding of network structure. To bring attention to these potentially problematic areas present in the drawing, this paper presents a technique that highlights common types of visual ambiguities: ambiguous spatial relationships between nodes and edges, visual overlap between community structures, and ambiguity in edge bundling and metanodes. Metrics, including newly proposed metrics for abnormal edge lengths, visual overlap in community structures and node/edge aggregation, are proposed to quantify areas of ambiguity in the drawing. These metrics and others are then displayed using a heatmap-based visualization that provides visual feedback to developers of graph drawing and visualization approaches, allowing them to quickly identify misleading areas. The novel metrics and the heatmap-based visualization allow a user to explore ambiguities in graph layouts frommultiple perspectives in order to make reasonable graph layout choices. The effectiveness of the technique is demonstrated through case studies and expert reviews}, number={1}, journal={IEEE Transactions on Visualization and Computer Graphics}, author={Wang, Yong and Shen, Qiaomu and Archambault, Daniel and Zhou, Zhiguang and Zhu, Min and Yang, Sixiao and Qu, Huamin}, year={2016}, pages={359–368} }

@article{Noack_2009, title={Modularity clustering is force-directed layout}, volume={79}, ISSN={15393755}, DOI={10.1103/PhysRevE.79.026102}, abstractNote={Two natural and widely used representations for the community structure of networks are clusterings, which partition the vertex set into disjoint subsets, and layouts, which assign the vertices to positions in a metric space. This paper unifies prominent characterizations of layout quality and clustering quality, by showing that energy models of pairwise attraction and repulsion subsume Newman and Girvan’s modularity measure. Layouts with optimal energy are relaxations of, and are thus consistent with, clusterings with optimal modularity, which is of practical relevance because both representations are complementary and often used together.}, note={arXiv: 0807.4052 ISBN: 1539-3755}, number={2}, journal={Physical Review E - Statistical, Nonlinear, and Soft Matter Physics}, author={Noack, Andreas}, year={2009} }

@article{Krzywinski_Birol_Jones_Marra_2012, title={Hive plots—rational approach to visualizing networks}, volume={13}, ISSN={1467-5463}, DOI={10.1093/bib/bbr069}, abstractNote={Networks are typically visualized with force-based or spectral layouts. These algorithms lack reproducibility and perceptual uniformity because they do not use a node coordinate system. The layouts can be difficult to interpret and are unsuitable for assessing differences in networks. To address these issues, we introduce hive plots (http://www.hiveplot.com) for generating informative, quantitative and comparable network layouts. Hive plots depict network structure transparently, are simple to understand and can be easily tuned to identify patterns of interest. The method is computationally straightforward, scales well and is amenable to a plugin for existing tools.}, number={5}, journal={Briefings in Bioinformatics}, author={Krzywinski, Martin and Birol, Inanc and Jones, Steven JM and Marra, Marco A}, year={2012}, month=sep, pages={627–644} }
