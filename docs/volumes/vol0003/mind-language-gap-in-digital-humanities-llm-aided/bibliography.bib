@inproceedings{arcanOntologyLabelTranslation2013,
  title = {Ontology {{Label Translation}}},
  booktitle = {Proceedings of the 2013 {{NAACL HLT Student Research Workshop}}},
  author = {Arcan, Mihael and Buitelaar, Paul},
  editor = {Louis, Annie and Socher, Richard and Hockenmaier, Julia and Ringger, Eric K.},
  year = {2013},
  month = jun,
  pages = {40--46},
  publisher = {Association for Computational Linguistics},
  address = {Atlanta, Georgia},
  langid = {english},
  keywords = {ontology translation},
}

@misc{arcanTranslatingTerminologicalExpressions2019,
  title = {Translating {{Terminological Expressions}} in {{Knowledge Bases}} with {{Neural Machine Translation}}},
  author = {Arcan, Mihael and Torregrosa, Daniel and Buitelaar, Paul},
  year = {2019},
  month = jul,
  number = {arXiv:1709.02184},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.1709.02184},
  abstract = {Our work presented in this paper focuses on the translation of terminological expressions represented in semantically structured resources, like ontologies or knowledge graphs. The challenge of translating ontology labels or terminological expressions documented in knowledge bases lies in the highly specific vocabulary and the lack of contextual information, which can guide a machine translation system to translate ambiguous words into the targeted domain. Due to these challenges, we evaluate the translation quality of domain-specific expressions in the medical and financial domain with statistical as well as with neural machine translation methods and experiment domain adaptation of the translation models with terminological expressions only. Furthermore, we perform experiments on the injection of external terminological expressions into the translation systems. Through these experiments, we observed a significant advantage in domain adaptation for the domain-specific resource in the medical and financial domain and the benefit of subword models over word-based neural machine translation models for terminology translation.},
  archiveprefix = {arXiv},
  keywords = {ontology translation,paper model},
}

@inproceedings{banarTransferLearningDigital2020,
  title = {Transfer {{Learning}} for {{Digital Heritage Collections}}: {{Comparing Neural Machine Translation}} at the {{Subword-level}} and {{Character-level}}:},
  shorttitle = {Transfer {{Learning}} for {{Digital Heritage Collections}}},
  booktitle = {Proceedings of the 12th {{International Conference}} on {{Agents}} and {{Artificial Intelligence}}},
  author = {Banar, Nikolay and Lasaracina, Karine and Daelemans, Walter and Kestemont, Mike},
  year = {2020},
  pages = {522--529},
  publisher = {{SCITEPRESS - Science and Technology Publications}},
  address = {Valletta, Malta},
  doi = {10.5220/0009167205220529},
  abstract = {Transfer learning via pre-training has become an important strategy for the efficient application of NLP methods in domains where only limited training data is available. This paper reports on a focused case study in which we apply transfer learning in the context of neural machine translation (French--Dutch) for cultural heritage metadata (i.e. titles of artistic works). Nowadays, neural machine translation (NMT) is commonly applied at the subword level using byte-pair encoding (BPE), because word-level models struggle with rare and out-of-vocabulary words. Because unseen vocabulary is a significant issue in domain adaptation, BPE seems a better fit for transfer learning across text varieties. We discuss an experiment in which we compare a subword-level to a character-level NMT approach. We pre-trained models on a large, generic corpus and fine-tuned them in a two-stage process: first, on a domain-specific dataset extracted from Wikipedia, and then on our metadata. While our experiments show comparable performance for character-level and BPEbased models on the general dataset, we demonstrate that the character-level approach nevertheless yields major downstream performance gains during the subsequent stages of fine-tuning. We therefore conclude that character-level translation can be beneficial compared to the popular subword-level approach in the cultural heritage domain.},
  langid = {english},
}

@article{bojanowskiEnrichingWordVectors2017,
  title = {Enriching {{Word Vectors}} with {{Subword Information}}},
  author = {Bojanowski, Piotr and Grave, Edouard and Joulin, Armand and Mikolov, Tomas},
  editor = {Lee, Lillian and Johnson, Mark and Toutanova, Kristina},
  year = {2017},
  journal = {Transactions of the Association for Computational Linguistics},
  volume = {5},
  pages = {135--146},
  publisher = {MIT Press},
  address = {Cambridge, MA},
  doi = {10.1162/tacl_a_00051},
  abstract = {Continuous word representations, trained on large unlabeled corpora are useful for many natural language processing tasks. Popular models that learn such representations ignore the morphology of words, by assigning a distinct vector to each word. This is a limitation, especially for languages with large vocabularies and many rare words. In this paper, we propose a new approach based on the skipgram model, where each word is represented as a bag of character n-grams. A vector representation is associated to each character n-gram; words being represented as the sum of these representations. Our method is fast, allowing to train models on large corpora quickly and allows us to compute word representations for words that did not appear in the training data. We evaluate our word representations on nine different languages, both on word similarity and analogy tasks. By comparing to recently proposed morphological word representations, we show that our vectors achieve state-of-the-art performance on these tasks.},
  keywords = {fasttext,word embedding},
}

@inproceedings{brownLanguageModelsAre2020,
  title = {Language Models Are Few-Shot Learners},
  booktitle = {Proceedings of the 34th {{International Conference}} on {{Neural Information Processing Systems}}},
  author = {Brown, Tom B. and Mann, Benjamin and Ryder, Nick and Subbiah, Melanie and Kaplan, Jared and Dhariwal, Prafulla and Neelakantan, Arvind and Shyam, Pranav and Sastry, Girish and Askell, Amanda and Agarwal, Sandhini and {Herbert-Voss}, Ariel and Krueger, Gretchen and Henighan, Tom and Child, Rewon and Ramesh, Aditya and Ziegler, Daniel M. and Wu, Jeffrey and Winter, Clemens and Hesse, Christopher and Chen, Mark and Sigler, Eric and Litwin, Mateusz and Gray, Scott and Chess, Benjamin and Clark, Jack and Berner, Christopher and McCandlish, Sam and Radford, Alec and Sutskever, Ilya and Amodei, Dario},
  year = {2020},
  month = dec,
  series = {{{NIPS}} '20},
  pages = {1877--1901},
  publisher = {Curran Associates Inc.},
  address = {Red Hook, NY, USA},
  abstract = {We demonstrate that scaling up language models greatly improves task-agnostic, few-shot performance, sometimes even becoming competitive with prior state-of-the-art fine-tuning approaches. Specifically, we train GPT-3, an autoregressive language model with 175 billion parameters, 10x more than any previous non-sparse language model, and test its performance in the few-shot setting. For all tasks, GPT-3 is applied without any gradient updates or fine-tuning, with tasks and few-shot demonstrations specified purely via text interaction with the model. GPT-3 achieves strong performance on many NLP datasets, including translation, question-answering, and cloze tasks. We also identify some datasets where GPT-3's few-shot learning still struggles, as well as some datasets where GPT-3 faces methodological issues related to training on large web corpora.},
  isbn = {978-1-7138-2954-6},
}

@inproceedings{christenComparisonPersonalName2006,
  title = {A {{Comparison}} of {{Personal Name Matching}}: {{Techniques}} and {{Practical Issues}}},
  shorttitle = {A {{Comparison}} of {{Personal Name Matching}}},
  booktitle = {Sixth {{IEEE International Conference}} on {{Data Mining}} - {{Workshops}} ({{ICDMW}}'06)},
  author = {Christen, Peter},
  year = {2006},
  pages = {290--294},
  publisher = {IEEE},
  address = {Hong Kong, China},
  doi = {10.1109/ICDMW.2006.2},
  abstract = {Finding and matching personal names is at the core of an increasing number of applications: from text and Web mining, information retrieval and extraction, search engines, to deduplication and data linkage systems. Variations and errors in names make exact string matching problematic, and approximate matching techniques based on phonetic encoding or pattern matching have to be applied. When compared to general text, however, personal names have different characteristics that need to be considered.},
  langid = {english},
  keywords = {distance measures,jaro-winkler,levenshtein},
}

@article{espinozaLabelTranslatorToolAutomatically2008,
  title = {{{LabelTranslator}} - {{A}} Tool to Automatically Localize an Ontology: 5th {{European Semantic Web Conference}}, {{ESWC}} 2008},
  shorttitle = {{{LabelTranslator}} - {{A}} Tool to Automatically Localize an Ontology},
  author = {Espinoza, Mauricio and {G{\'o}mez-P{\'e}rez}, Asunci{\'o}n and Mena, Eduardo},
  year = {2008},
  journal = {The Semantic Web},
  series = {Lecture {{Notes}} in {{Computer Science}} (Including Subseries {{Lecture Notes}} in {{Artificial Intelligence}} and {{Lecture Notes}} in {{Bioinformatics}})},
  pages = {792--796},
  doi = {10.1007/978-3-540-68234-9_60},
  abstract = {This demo proposal briefly presents LabelTranslator, a system that suggests translations of ontology labels, with the purpose of localizing ontologies. LabelTranslator takes as input an ontology whose labels are described in a source natural language and obtains the most probable translation of each ontology label into a target natural language. Our main contribution is the automatization of this process, which reduces human efforts to localize manually the ontology.},
  keywords = {ontology translation},
}

@book{euzenatOntologyMatching2013,
  title = {Ontology {{Matching}}},
  author = {Euzenat, J{\'e}r{\^o}me and Shvaiko, Pavel},
  year = {2013},
  edition = {second edition},
  publisher = {Springer},
  address = {Berlin, Heidelberg},
  doi = {10.1007/978-3-642-38721-0},
  langid = {english},
  keywords = {oaei,ontology matching},
}

@inproceedings{fengEnglishChineseKnowledgeBase2016,
  title = {English-{{Chinese Knowledge Base Translation}} with {{Neural Network}}},
  booktitle = {Proceedings of {{COLING}} 2016, the 26th {{International Conference}} on {{Computational Linguistics}}: {{Technical Papers}}},
  author = {Feng, Xiaocheng and Tang, Duyu and Qin, Bing and Liu, Ting},
  editor = {Matsumoto, Yuji and Prasad, Rashmi},
  year = {2016},
  month = dec,
  pages = {2935--2944},
  publisher = {The COLING 2016 Organizing Committee},
  address = {Osaka, Japan},
  abstract = {Knowledge base (KB) such as Freebase plays an important role for many natural language processing tasks. English knowledge base is obviously larger and of higher quality than low resource language like Chinese. To expand Chinese KB by leveraging English KB resources, an effective way is to translate English KB (source) into Chinese (target). In this direction, two major challenges are to model triple semantics and to build a robust KB translator. We address these challenges by presenting a neural network approach, which learns continuous triple representation with a gated neural network. Accordingly, source triples and target triples are mapped in the same semantic vector space. We build a new dataset for English-Chinese KB translation from Freebase, and compare with several baselines on it. Experimental results show that the proposed method improves translation accuracy compared with baseline methods. We show that adaptive composition model improves standard solution such as neural tensor network in terms of translation accuracy.},
  keywords = {ontology translation,paper model},
}

@article{florrenceMLGrafVizMultilingualOntology2021,
  title = {{{MLGrafViz}}: {{Multilingual}} Ontology Visualization Plug-in for Prot{\'e}g{\'e}},
  shorttitle = {{{MLGrafViz}}},
  author = {Florrence, Merlin},
  year = {2021},
  month = mar,
  journal = {Computer Science and Information Technologies},
  volume = {2},
  number = {1},
  pages = {43--48},
  doi = {10.11591/csit.v2i1.p43-48},
  abstract = {Natural language processing (NLP) is rapidly increasing in all domains of knowledge acquisition to facilitate different language user. It is required to develop knowledge based NLP systems to provide better results. Knowledge based systems can be implemented using ontologies where ontology is a collection of terms and concepts arranged taxonomically. The concepts that are visualized graphically are more understandable than in the text form. ~In this research paper, new multilingual ontology visualization plug-in MLGrafViz is developed to visualize ontologies in different natural languages. This plug-in is developed for prot{\'e}g{\'e} ontology editor. This plug-in allows the user to translate and visualize the core ontology into 135 languages.},
  copyright = {Copyright (c) 2021 Institute of Advanced Engineering and Science},
  langid = {english},
  keywords = {ontology translation},
}

@incollection{haslhoferKnowledgeGraphsLibraries2018,
  title = {Knowledge {{Graphs}} in the {{Libraries}} and {{Digital Humanities Domain}}},
  booktitle = {Encyclopedia of {{Big Data Technologies}}},
  author = {Haslhofer, Bernhard and Isaac, Antoine and Simon, Rainer},
  editor = {Sakr, Sherif and Zomaya, Albert},
  year = {2018},
  pages = {1--8},
  publisher = {Springer International Publishing},
  address = {Cham},
  doi = {10.1007/978-3-319-63962-8_291-1},
  langid = {english},
  keywords = {Digital Humanities,knowledge graph},
}

@inproceedings{heinzerlingBPEmbTokenizationfreePretrained2018,
  title = {{{BPEmb}}: {{Tokenization-free Pre-trained Subword Embeddings}} in 275 {{Languages}}},
  shorttitle = {{{BPEmb}}},
  booktitle = {Proceedings of the {{Eleventh International Conference}} on {{Language Resources}} and {{Evaluation}} ({{LREC}} 2018)},
  author = {Heinzerling, Benjamin and Strube, Michael},
  editor = {Calzolari, Nicoletta and Choukri, Khalid and Cieri, Christopher and Declerck, Thierry and Goggi, Sara and Hasida, Koiti and Isahara, Hitoshi and Maegaard, Bente and Mariani, Joseph and Mazo, H{\'e}l{\`e}ne and Moreno, Asuncion and Odijk, Jan and Piperidis, Stelios and Tokunaga, Takenobu},
  year = {2018},
  month = may,
  publisher = {European Language Resources Association (ELRA)},
  address = {Miyazaki, Japan},
  langid = {english},
  keywords = {bpemb,word embedding},
}

@article{jaroAdvancesRecordLinkageMethodology1989,
  title = {Advances in {{Record-Linkage Methodology}} as {{Applied}} to {{Matching}} the 1985 {{Census}} of {{Tampa}}, {{Florida}}},
  author = {Jaro, Matthew A.},
  year = {1989},
  month = jun,
  journal = {Journal of the American Statistical Association},
  volume = {84},
  number = {406},
  pages = {414--420},
  publisher = {ASA Website},
  doi = {10.1080/01621459.1989.10478785},
  abstract = {A test census of Tampa, Florida and an independent postenumeration survey (PES) were conducted by the U.S. Census Bureau in 1985. The PES was a stratified block sample with heavy emphasis placed on hard-to-count population groups. Matching the individuals in the census to the individuals in the PES is an important aspect of census coverage evaluation and consequently a very important process for any census adjustment operations that might be planned. For such an adjustment to be feasible, record-linkage software had to be developed that could perform matches with a high degree of accuracy and that was based on an underlying mathematical theory. A principal purpose of the PES was to provide an opportunity to evaluate the newly implemented record-linkage system and associated methodology. This article discusses the theoretical and practical issues encountered in conducting the matching operation and presents the results of that operation. A review of the theoretical background of the record-linkage problem provides a framework for discussions of the decision procedure, file blocking, and the independence assumption. The estimation of the parameters required by the decision procedure is an important aspect of the methodology, and the techniques presented provide a practical system that is easily implemented. The matching algorithm (discussed in detail) uses the linear sum assignment model to ``pair'' the records. The Tampa, Florida, matching methodology is described in the final sections of the article. Included in the discussion are the results of the matching itself, an independent clerical review of the matches and nonmatches, conclusions, problem areas, and future work required.}
}

@misc{jiaoChatGPTGoodTranslator2023,
  title = {Is {{ChatGPT A Good Translator}}? {{Yes With GPT-4 As The Engine}}},
  shorttitle = {Is {{ChatGPT A Good Translator}}?},
  author = {Jiao, Wenxiang and Wang, Wenxuan and Huang, Jen-tse and Wang, Xing and Shi, Shuming and Tu, Zhaopeng},
  year = {2023},
  month = nov,
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2301.08745},
  abstract = {This report provides a preliminary evaluation of ChatGPT for machine translation, including translation prompt, multilingual translation, and translation robustness. We adopt the prompts advised by ChatGPT to trigger its translation ability and find that the candidate prompts generally work well with minor performance differences. By evaluating on a number of benchmark test sets, we find that ChatGPT performs competitively with commercial translation products (e.g., Google Translate) on high-resource European languages but lags behind significantly on low-resource or distant languages. As for the translation robustness, ChatGPT does not perform as well as the commercial systems on biomedical abstracts or Reddit comments but exhibits good results on spoken language. Further, we explore an interesting strategy named pivot prompting for distant languages, which asks ChatGPT to translate the source sentence into a high-resource pivot language before into the target language, improving the translation performance noticeably. With the launch of the GPT-4 engine, the translation performance of ChatGPT is significantly boosted, becoming comparable to commercial translation products, even for distant languages. Human analysis on Google Translate and ChatGPT suggests that ChatGPT with GPT-3.5 tends to generate more hallucinations and mis-translation errors while that with GPT-4 makes the least errors. In other words, ChatGPT has already become a good translator. Please refer to our Github project for more details: https://github.com/wxjiao/ Is-ChatGPT-A-Good-Translator.},
  archiveprefix = {arXiv},
  langid = {english},
}

@inproceedings{kimWhenWhyUnsupervised2020,
  title = {When and {{Why}} Is {{Unsupervised Neural Machine Translation Useless}}?},
  booktitle = {Proceedings of the 22nd {{Annual Conference}} of the {{European Association}} for {{Machine Translation}}},
  author = {Kim, Yunsu and Gra{\c c}a, Miguel and Ney, Hermann},
  editor = {Martins, Andr{\'e} and Moniz, Helena and Fumega, Sara and Martins, Bruno and Batista, Fernando and Coheur, Luisa and Parra, Carla and Trancoso, Isabel and Turchi, Marco and Bisazza, Arianna and Moorkens, Joss and Guerberof, Ana and Nurminen, Mary and Marg, Lena and Forcada, Mikel L.},
  year = {2020},
  month = nov,
  pages = {35--44},
  publisher = {European Association for Machine Translation},
  address = {Lisboa, Portugal},
  abstract = {This paper studies the practicality of the current state-of-the-art unsupervised methods in neural machine translation (NMT). In ten translation tasks with various data settings, we analyze the conditions under which the unsupervised methods fail to produce reasonable translations. We show that their performance is severely affected by linguistic dissimilarity and domain mismatch between source and target monolingual data. Such conditions are common for low-resource language pairs, where unsupervised learning works poorly. In all of our experiments, supervised and semi-supervised baselines with 50k-sentence bilingual data outperform the best unsupervised results. Our analyses pinpoint the limits of the current unsupervised NMT and also suggest immediate research directions.},
}

@inproceedings{krausGoldStandardBenchmark2024,
  title = {A {{Gold Standard Benchmark Dataset}} for {{Digital Humanities}}},
  booktitle = {Proceedings of the 19th {{International Workshop}} on {{Ontology Matching}}},
  author = {Kraus, Felix and Blumenr{\"o}hr, Nicolas and G{\"o}tzelmann, Germaine and Tonne, Danah and Streit, Achim},
  editor = {{Jim{\'e}nez-Ruiz}, Ernesto and Hassanzadeh, Oktie and Trojahn, C{\'a}ssia and Hertling, Sven and Li, Huanyu and Shvaiko, Pavel and Euzenat, J{\'e}r{\^o}me},
  year = {2024},
  month = nov,
  series = {{{CEUR Workshop Proceedings}}},
  volume = {3897},
  pages = {1--17},
  publisher = {CEUR},
  address = {Baltimore, MD, USA},
  doi = {10.5445/IR/1000178023},
  langid = {english},
}

@misc{leeGeminiEmbeddingGeneralizable2025,
  title = {Gemini {{Embedding}}: {{Generalizable Embeddings}} from {{Gemini}}},
  shorttitle = {Gemini {{Embedding}}},
  author = {Lee, Jinhyuk and Chen, Feiyang and Dua, Sahil and Cer, Daniel and Shanbhogue, Madhuri and Naim, Iftekhar and {\'A}brego, Gustavo Hern{\'a}ndez and Li, Zhe and Chen, Kaifeng and Vera, Henrique Schechter and Ren, Xiaoqi and Zhang, Shanfeng and Salz, Daniel and Boratko, Michael and Han, Jay and Chen, Blair and Huang, Shuo and Rao, Vikram and Suganthan, Paul and Han, Feng and Doumanoglou, Andreas and Gupta, Nithi and Moiseev, Fedor and Yip, Cathy and Jain, Aashi and Baumgartner, Simon and Shahi, Shahrokh and Gomez, Frank Palma and Mariserla, Sandeep and Choi, Min and Shah, Parashar and Goenka, Sonam and Chen, Ke and Xia, Ye and Chen, Koert and Duddu, Sai Meher Karthik and Chen, Yichang and Walker, Trevor and Zhou, Wenlei and Ghiya, Rakesh and Gleicher, Zach and Gill, Karan and Dong, Zhe and Seyedhosseini, Mojtaba and Sung, Yunhsuan and Hoffmann, Raphael and Duerig, Tom},
  year = {2025},
  month = mar,
  number = {arXiv:2503.07891},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2503.07891},
  abstract = {In this report, we introduce Gemini Embedding, a state-of-the-art embedding model leveraging the power of Gemini, Google's most capable large language model. Capitalizing on Gemini's inherent multilingual and code understanding capabilities, Gemini Embedding produces highly generalizable embeddings for text spanning numerous languages and textual modalities. The representations generated by Gemini Embedding can be precomputed and applied to a variety of downstream tasks including classification, similarity, clustering, ranking, and retrieval. Evaluated on the Massive Multilingual Text Embedding Benchmark (MMTEB), which includes over one hundred tasks across 250+ languages, Gemini Embedding substantially outperforms prior state-of-the-art models, demonstrating considerable improvements in embedding quality. Achieving state-of-the-art performance across MMTEB's multilingual, English, and code benchmarks, our unified model demonstrates strong capabilities across a broad selection of tasks and surpasses specialized domain-specific models.},
  archiveprefix = {arXiv},
  langid = {english},
}

@article{levenshteinBinaryCodesCapable1966,
  title = {Binary Codes Capable of Correcting Deletions, Insertions, and Reversals},
  author = {Levenshtein, Vladimir I.},
  year = {1966},
  journal = {Soviet Physics Doklady},
  volume = {10},
  number = {8},
  pages = {707--710},
  langid = {english},
}

@article{liuMultilingualDenoisingPretraining2020,
  title = {Multilingual {{Denoising Pre-training}} for {{Neural Machine Translation}}},
  author = {Liu, Yinhan and Gu, Jiatao and Goyal, Naman and Li, Xian and Edunov, Sergey and Ghazvininejad, Marjan and Lewis, Mike and Zettlemoyer, Luke},
  year = {2020},
  month = dec,
  journal = {Transactions of the Association for Computational Linguistics},
  volume = {8},
  pages = {726--742},
  doi = {10.1162/tacl_a_00343},
  abstract = {This paper demonstrates that multilingual denoising pre-training produces significant performance gains across a wide variety of machine translation (MT) tasks. We present mBART---a sequence-to-sequence denoising auto-encoder pre-trained on large-scale monolingual corpora in many languages using the BART objective (Lewis et al., 2019 ). mBART is the first method for pre-training a complete sequence-to-sequence model by denoising full texts in multiple languages, whereas previous approaches have focused only on the encoder, decoder, or reconstructing parts of the text. Pre-training a complete model allows it to be directly fine-tuned for supervised (both sentence-level and document-level) and unsupervised machine translation, with no task- specific modifications. We demonstrate that adding mBART initialization produces performance gains in all but the highest-resource settings, including up to 12 BLEU points for low resource MT and over 5 BLEU points for many document-level and unsupervised models. We also show that it enables transfer to language pairs with no bi-text or that were not in the pre-training corpus, and present extensive analysis of which factors contribute the most to effective pre-training.               1},
  langid = {english},
}

@inproceedings{manakhimovaLinguisticallyMotivatedEvaluation2023,
  title = {Linguistically {{Motivated Evaluation}} of the 2023 {{State-of-the-art Machine Translation}}: {{Can ChatGPT Outperform NMT}}?},
  shorttitle = {Linguistically {{Motivated Evaluation}} of the 2023 {{State-of-the-art Machine Translation}}},
  booktitle = {Proceedings of the {{Eighth Conference}} on {{Machine Translation}}},
  author = {Manakhimova, Shushen and Avramidis, Eleftherios and Macketanz, Vivien and {Lapshinova-Koltunski}, Ekaterina and Bagdasarov, Sergei and M{\"o}ller, Sebastian},
  year = {2023},
  pages = {224--245},
  publisher = {Association for Computational Linguistics},
  address = {Singapore},
  doi = {10.18653/v1/2023.wmt-1.23},
  abstract = {This paper offers a fine-grained analysis of the machine translation outputs in the context of the Shared Task at the 8th Conference of Machine Translation (WMT23). Building on the foundation of previous test suite efforts, our analysis includes Large Language Models and an updated test set featuring new linguistic phenomena. To our knowledge, this is the first fine-grained linguistic analysis for the GPT-4 (5-shot) translation outputs. Our evaluation spans German--English, English--German, and English--Russian language directions. Some of the phenomena with the lowest accuracies for German--English are idioms and resultative predicates. For English--German, these include mediopassive voice, and noun formation(er). As for English--Russian, these included idioms and semantic roles. GPT-4 (5shot) performs equally or comparably to the best systems in German--English and English--German but falls in the second significance cluster for English--Russian.},
  langid = {english},
}

@inproceedings{mauserExtendingStatisticalMachine2009,
  title = {Extending {{Statistical Machine Translation}} with {{Discriminative}} and {{Trigger-Based Lexicon Models}}},
  booktitle = {Proceedings of the 2009 {{Conference}} on {{Empirical Methods}} in {{Natural Language Processing}}},
  author = {Mauser, Arne and Hasan, Sa{\v s}a and Ney, Hermann},
  editor = {Koehn, Philipp and Mihalcea, Rada},
  year = {2009},
  month = aug,
  pages = {210--218},
  publisher = {Association for Computational Linguistics},
  address = {Singapore},
  keywords = {ontology translation},
}

@book{milesSKOSSimpleKnowledge2009,
  title = {{{SKOS}} Simple Knowledge Organization System Reference},
  author = {Miles, Alistair and Bechhofer, Sean},
  year = {2009},
  month = aug,
  series = {{{W3C}} Recommendation},
  publisher = {World Wide Web Consortium},
  address = {United States},
  abstract = {This document defines the Simple Knowledge Organization System (SKOS), a common data model for sharing and linking knowledge organization systems via the Web.Many knowledge organization systems, such as thesauri, taxonomies, classification schemes and subject heading systems, share a similar structure, and are used in similar applications. SKOS captures much of this similarity and makes it explicit, to enable data and technology sharing across diverse applications.The SKOS data model provides a standard, low-cost migration path for porting existing knowledge organization systems to the Semantic Web. SKOS also provides a lightweight, intuitive language for developing and sharing new knowledge organization systems. It may be used on its own, or in combination with formal knowledge representation languages such as the Web Ontology language (OWL).This document is the normative specification of the Simple Knowledge Organization System. It is intended for readers who are involved in the design and implementation of information systems, and who already have a good understanding of Semantic Web technology, especially RDF and OWL.For an informative guide to using SKOS, see the [SKOS-PRIMER].},
  langid = {english},
  keywords = {SKOS,W3C}
}

@inproceedings{morvilloIntegratingMultipleKnowledge2024,
  title = {Integrating Multiple Knowledge Graphs in {{Digital Humanities}}},
  booktitle = {{{ST4DM}} 2024: {{Semantic Technologies}} for {{Data Management}}},
  author = {Morvillo, Alberto and Mecella, Massimo},
  year = {2024},
  month = jul,
  address = {Twente, Italy},
  abstract = {In the field of digital humanities, the mode of information consumption constitutes a fundamental factor in the quality of research. The structuring of data into knowledge graphs provides a valuable tool for navigating concepts and exploring new ideas. However, sources might be generated with different structural definitions, which could result in fragmented knowledge. The integration of various knowledge graphs helps in reducing such fragmentation, but if not carried out in real-time it is a costly operation with limited flexibility. In this paper, a real-time approach for integrating multiple knowledge graphs into content navigation results is discussed.},
  langid = {english},
  keywords = {Digital Humanities,knowledge graph},
}

@article{moussallemMachineTranslationUsing2018,
  title = {Machine {{Translation}} Using {{Semantic Web Technologies}}: {{A Survey}}},
  shorttitle = {Machine {{Translation}} Using {{Semantic Web Technologies}}},
  author = {Moussallem, Diego and Wauer, Matthias and Ngomo, Axel-Cyrille Ngonga},
  year = {2018},
  month = aug,
  journal = {Journal of Web Semantics},
  volume = {51},
  primaryclass = {cs},
  pages = {1--19},
  doi = {10.1016/j.websem.2018.07.001},
  abstract = {A large number of machine translation approaches have recently been developed to facilitate the fluid migration of content across languages. However, the literature suggests that many obstacles must still be dealt with to achieve better automatic translations. One of these obstacles is lexical and syntactic ambiguity. A promising way of overcoming this problem is using Semantic Web technologies. This article presents the results of a systematic review of machine translation approaches that rely on Semantic Web technologies for translating texts. Overall, our survey suggests that while Semantic Web technologies can enhance the quality of machine translation outputs for various problems, the combination of both is still in its infancy.},
  archiveprefix = {arXiv},
  langid = {english},
  keywords = {machine translation,ontology translation,survey},
}

@inproceedings{moussallemTHOTHNeuralTranslation2019,
  title = {{{THOTH}}: {{Neural Translation}} and {{Enrichment}} of {{Knowledge Graphs}}},
  shorttitle = {{{THOTH}}},
  booktitle = {The {{Semantic Web}} -- {{ISWC}} 2019: 18th {{International Semantic Web Conference}}, {{Auckland}}, {{New Zealand}}, {{October}} 26--30, 2019, {{Proceedings}}, {{Part I}}},
  author = {Moussallem, Diego and Soru, Tommaso and Ngonga~Ngomo, Axel-Cyrille},
  year = {2019},
  month = oct,
  pages = {505--522},
  publisher = {Springer-Verlag},
  address = {Berlin, Heidelberg},
  doi = {10.1007/978-3-030-30793-6_29},
  abstract = {Knowledge Graphs are used in an increasing number of applications. Although considerable human effort has been invested into making knowledge graphs available in multiple languages, most knowledge graphs are in English. Additionally, regional facts are often only available in the language of the corresponding region. This lack of multilingual knowledge availability clearly limits the porting of machine learning models to different languages. In this paper, we aim to alleviate this drawback by proposing THOTH, an approach for translating and enriching knowledge graphs. THOTH extracts bilingual alignments between a source and target knowledge graph and learns how to translate from one to the other by relying on two different recurrent neural network models along with knowledge graph embeddings. We evaluated THOTH extrinsically by comparing the German DBpedia with the German translation of the English DBpedia on two tasks: fact checking and entity linking. In addition, we ran a manual intrinsic evaluation of the translation. Our results show that THOTH is a promising approach which achieves a translation accuracy of 88.56\%. Moreover, its enrichment improves the quality of the German DBpedia significantly, as we report +18.4\% accuracy for fact validation and +19\% F for entity linking.},
  keywords = {figure model,ontology translation,paper model},
}

@inproceedings{pourResultsOntologyAlignment2024,
  title = {Results of the {{Ontology Alignment Evaluation Initiative}} 2024},
  booktitle = {Proceedings of the 19th {{International Workshop}} on {{Ontology Matching}} ({{OM}} 2024), {{Baltimore}}, {{USA}}, {{November}} 11, 2024. {{Ed}}.: {{E}}. {{Jim{\'e}nez-Ruiz}}, {{O}}. {{Hassanzadeh}}, {{C}}. {{Trojahn}}, {{S}}. {{Hertling}}, {{H}}. {{Li}}, {{P}}. {{Shvaiko}}, {{J}}. {{Euzenat}}},
  author = {Pour, Mina Abd Nikooie and Algergawy, Alsayed and Blomqvist, Eva and Buche, Patrice and Chen, Jiaoyan and Cotovio, Pedro Giesteira and Coulet, Adrien and Cufi, Julien and Dong, Hang and Faria, Daniel and Ferraz, Lucas and Hertling, Sven and He, Yuan and Horrocks, Ian and Ibanescu, Liliana and Jain, Sarika and {Jim{\'e}nez-Ruiz}, Ernesto and Karam, Naouel and Kraus, Felix and Lambrix, Patrick and Li, Huanyu and Li, Ying and Monnin, Pierre and Paulheim, Heiko and Pesquita, Catia and Sharma, Abhisek and Shvaiko, Pavel and Silva, Marta and Sousa, Guilherme and Trojahn, Cassia and Vata{\v s}{\v c}inov{\'a}, Jana and Yaman, Beyza and Zamazal, Ond{\v r}ej and Zhou, Lu},
  year = {2024},
  month = nov,
  series = {{{CEUR Workshop Proceedings}}},
  volume = {3897},
  pages = {64--97},
  publisher = {CEUR},
  address = {Baltimore, MD, USA},
  doi = {10.5445/IR/1000179469},
  abstract = {The Ontology Alignment Evaluation Initiative (OAEI) aims at comparing ontology matching systems on precisely defined test cases. These test cases can be based on ontologies of different levels of complexity and use different evaluation modalities. The OAEI 2024 campaign offered 13 tracks and was attended by 13 participants. This paper is an overall presentation of that campaign.},
  langid = {english},
}

@inproceedings{renzeEffectSamplingTemperature2024,
  title = {The {{Effect}} of {{Sampling Temperature}} on {{Problem Solving}} in {{Large Language Models}}},
  booktitle = {Findings of the {{Association}} for {{Computational Linguistics}}: {{EMNLP}} 2024},
  author = {Renze, Matthew},
  editor = {{Al-Onaizan}, Yaser and Bansal, Mohit and Chen, Yun-Nung},
  year = {2024},
  month = nov,
  pages = {7346--7356},
  publisher = {Association for Computational Linguistics},
  address = {Miami, Florida, USA},
  doi = {10.18653/v1/2024.findings-emnlp.432},
  abstract = {In this research study, we empirically investigate the effect of sampling temperature on the performance of Large Language Models (LLMs) on various problem-solving tasks. We created a multiple-choice question-and-answer (MCQA) exam by randomly sampling problems from standard LLM benchmarks. Then, we used nine popular LLMs with five prompt-engineering techniques to solve the MCQA problems while increasing the sampling temperature from 0.0 to 1.6. Despite anecdotal reports to the contrary, our empirical results indicate that changes in temperature from 0.0 to 1.0 do not have a statistically significant impact on LLM performance for problem-solving tasks. In addition, these results appear to generalize across LLMs, prompt-engineering techniques, and problem domains. All code, data, and supplemental materials are available on GitHub at: https://github.com/matthewrenze/jhu-llm-temperature},
}

@article{suissaTextAnalysisUsing2022,
  title = {Text Analysis Using Deep Neural Networks in Digital Humanities and Information Science},
  author = {Suissa, Omri and Elmalech, Avshalom and {Zhitomirsky-Geffet}, Maayan},
  year = {2022},
  journal = {Journal of the Association for Information Science and Technology},
  volume = {73},
  number = {2},
  pages = {268--287},
  doi = {10.1002/asi.24544},
  abstract = {Combining computational technologies and humanities is an ongoing effort aimed at making resources such as texts, images, audio, video, and other artifacts digitally available, searchable, and analyzable. In recent years, deep neural networks (DNN) dominate the field of automatic text analysis and natural language processing (NLP), in some cases presenting a super-human performance. DNNs are the state-of-the-art machine learning algorithms solving many NLP tasks that are relevant for Digital Humanities (DH) research, such as spell checking, language detection, entity extraction, author detection, question answering, and other tasks. These supervised algorithms learn patterns from a large number of ``right'' and ``wrong'' examples and apply them to new examples. However, using DNNs for analyzing the text resources in DH research presents two main challenges: (un)availability of training data and a need for domain adaptation. This paper explores these challenges by analyzing multiple use-cases of DH studies in recent literature and their possible solutions and lays out a practical decision model for DH experts for when and how to choose the appropriate deep learning approaches for their research. Moreover, in this paper, we aim to raise awareness of the benefits of utilizing deep learning models in the DH community.},
  copyright = {{\copyright} 2021 Association for Information Science and Technology.},
  langid = {english},
}

@inproceedings{thurmairComparingRulebasedStatistical2004,
  title = {Comparing Rule-Based and Statistical {{MT}} Output},
  booktitle = {Proceedings of the {{LREC}} 2004 {{Workshop}} on {{The Amazing Utility}} of {{Parallel}} and {{Comparable Corpora}}},
  author = {Thurmair, Gregor},
  year = {2004},
  pages = {5--9},
  address = {Lissabon},
  abstract = {This paper describes a comparison between a statistical and a rule-based MT system. The first section describes the setup and the evaluation results; the second section analyses the strengths and weaknesses of the respective approaches, and the third tries to define an architecture for a hybrid system, based on a rule-based backbone and enhanced by statistical intelligence.},
  langid = {english},
  keywords = {ontology translation},
}

@article{violaEditorialDataWorkflows2024,
  title = {Editorial: {{Data}} and {{Workflows}} for {{Multilingual Digital Humanities}}},
  shorttitle = {Editorial},
  author = {Viola, Lorella},
  year = {2024},
  month = jun,
  journal = {Journal of Open Humanities Data},
  volume = {10},
  pages = {37},
  doi = {10.5334/johd.220},
  abstract = {This Editorial presents the Special Collection `Data and Workflows for Multilingual Digital Humanities'. The Special Collection brings together an assortment of contributions that explore how power structures operate in digital knowledge production with a focus on multilingualism and the management of multilingual data. The seven articles in the Special Collection offer an overview of innovative approaches and results that highlight the richness and the challenges of the intersection between multilingualism and the digital realm for humanities research. They showcase innovative workflows for multilingual data acquisition, curation, integration, and analysis, reflecting the efforts of Multilingual Digital Humanities research to ensure broad participation and representation in digital knowledge production. `Data and Workflows for Multilingual Digital Humanities' contributes to make digital knowledge production more inclusive, equitable, and representative of global diversity.},
  langid = {english},
}

@article{winklerStringComparatorMetrics1990,
  title = {String {{Comparator Metrics}} and {{Enhanced Decision Rules}} in the {{Fellegi-Sunter Model}} of {{Record Linkage}}},
  author = {Winkler, William E.},
  year = {1990},
  month = jan,
  journal = {Proceedings of the Survey Research Methods Section, ASA (1990)},
  pages = {354--359},
  abstract = {To locate matches across pairs of lists without unique identifiers it is sometimes necessary to compare strings of letters. String comparators are used in production computer matching software during the Post Enumeration Survey for the 1990 U.S. census. A string comparator metric is described that partially accounts for: (1) typographical variation in strings such as first name or surname; (2) decision rules that use the string comparator; and (3) improvements in empirical matching results. The string comparator metric for comparing partially agreeing strings extends the Jaro string comparator. How general methods of accounting for partial agreement fit with the Fellegi-Sunter (I. P. Fellegi and A. B. Sunter, 1969) model of record linkage is described. A formal method of modeling  how to adjust matching weights between pure agreement and pure disagreement is presented. The procedure is illustrated for files for which the truth of matches is known. It is demonstrated that the theoretical rules of Fellegi and Sunter are still valid when general weighting adjustments accounting for partial agreement are performed. Eight tables contain illustrative data. (SLD)},
  langid = {english},
  annotation = {ERIC Number: ED325505},
}

@inproceedings{xueMT5MassivelyMultilingual2021,
  title = {{{mT5}}: {{A Massively Multilingual Pre-trained Text-to-Text Transformer}}},
  shorttitle = {{{mT5}}},
  booktitle = {Proceedings of the 2021 {{Conference}} of the {{North American Chapter}} of the {{Association}} for {{Computational Linguistics}}: {{Human Language Technologies}}},
  author = {Xue, Linting and Constant, Noah and Roberts, Adam and Kale, Mihir and {Al-Rfou}, Rami and Siddhant, Aditya and Barua, Aditya and Raffel, Colin},
  year = {2021},
  pages = {483--498},
  publisher = {Association for Computational Linguistics},
  address = {Online},
  doi = {10.18653/v1/2021.naacl-main.41},
  langid = {english},
}

@misc{zhou2024multilingual,
  title = {Multilingual {{MMLU}} Benchmark Leaderboard},
  author = {Zhou, Yi and Sakai, Yusuke and Zhou, Yongxin and Li, Haonan and Geng, Jiahui and Li, Qing and Li, Wenxi and Lin, Yuanyu and Way, Andy and Li, Zhuang and Wan, Zhongwei and Wu, Di and Lai, Wen and Zeng, Bo},
  year = {2024},
  publisher = {Hugging Face}
}
