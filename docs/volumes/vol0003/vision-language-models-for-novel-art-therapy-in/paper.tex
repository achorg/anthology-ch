\documentclass[final]{anthology-ch}

\usepackage{booktabs}
\usepackage{graphicx}

\title{Vision Language Models for Novel Art Therapy Evaluation in Schizophrenia}

\author[1,2]{Ivan Nenchev}[
orcid=0000-0002-9860-3250
]

\author[3]{Karin Dannecker}[
orcid=0009-0003-3031-5484
]

\author[1]{Maren Rabe}[
orcid=
]

\author[4]{Marie Jeschke}[
orcid=
]

\author[1]{Christiane Montag}[
orcid=0000-0002-3307-276X
]

\affiliation{1}{Department of Psychiatry and Psychotherapy, Charité at St. Hedwig Hospital, Charité – Universitätsmedizin Berlin, Berlin, Germany}
\affiliation{2}{Berlin Institute of Health at Charité – Universitätsmedizin Berlin, Berlin, Germany}
\affiliation{3}{Weißensee Kunsthochschule Berlin MA Art Therapy Programme, Berlin, Germany}
\affiliation{4}{Galerie ART CRU Berlin, Berlin, Germany}

\keywords{art therapy, schizophrenia, CLIP embeddings, vision language models, semantic analysis, longitudinal assessment}

\pubyear{2025}
\pubvolume{3}
\pagestart{310}
\pageend{321}
\conferencename{Computational Humanities Research 2025}
\conferenceeditors{Taylor Arnold, Margherita Fantoli, and Ruben Ros}
\doi{10.63744/sttzqxdNWsq1}
\paperorder{21}

\addbibresource{bibliography.bib}

\begin{document}

\maketitle

\begin{abstract}
Traditional methodologies for evaluating visual artistic output in art therapy remain rare and time-intensive, creating barriers to systematic assessment of therapeutic progress. This study presents the first application of multimodal dense embeddings for longitudinal evaluation of art therapy outcomes in individuals with schizophrenia. We analyzed 168 art therapy images produced by 14 participants with schizophrenia using CLIP (Contrastive Language-Image Pretraining) embeddings. CLIP embeddings successfully captured meaningful semantic patterns, with real images showing significantly greater semantic dispersion than spatially randomized controls. Longitudinal analysis revealed progressive semantic diversification over time, with significant increases in semantic distance between consecutive images ($\beta= 0.284$, $p = 0.001$) and cumulative semantic drift from first images ($\beta = 0.336$, $p < 0.001$). Individual differences analysis showed high variability in volume metrics spanning several orders of magnitude (M = 1.13 × 10¹¹, SD = 2.05 × 10¹¹), indicating highly individual semantic exploration patterns. Vision language models provide a novel and objective methodology for evaluating the progression of art therapy that reveals systematic patterns of semantic evolution during treatment. The progressive semantic diversification observed suggests that art therapy facilitates expanding creative expression and psychological exploration over time. The substantial individual differences in semantic exploration patterns indicate potential for personalized treatment approaches based on creative trajectory analysis. This methodology offers promising applications for systematic art therapy assessment, treatment monitoring, and personalized intervention strategies in clinical practice.
\end{abstract}

\section{Introduction}

Art therapy (AT) is the therapeutic use of visual art. Through drawing, painting, sculpting, and other media, visual works are created and processes are initiated that serve as symbolic equivalents of experiences, emotions, thoughts, and fantasies \cite{dannecker_psyche_2021}. These artworks help patients to perceive, understand, and communicate their conscious and unconscious conflicts and difficulties \cite{dannecker_why_2024}. The aesthetic-therapeutic process activates a person’s imaginative, cognitive, integrative, and motor capacities. AT supports emotional expression, stimulates thought processes and the ability to organize experience, and deepens empathy, introspection, relational capacities, and communication skills. The tangible and enduring nature of artistic works are particularly effective therapeutic factors, as they help patients develop a stronger sense of identity, autonomy, self-efficacy, and self-worth. As a therapeutic modality, AT serves as a valuable complement to traditional biological and psychological treatments and is implemented across a broad range of patients with psychiatric \cite{hu_art_2021} and somatic conditions \cite{zhou_effects_2023}.

Growing empirical evidence supports AT's clinical efficacy across diverse populations and conditions. A systematic review and meta-analysis of randomized clinical trials found that visual AT was associated with therapeutic benefits across several outcomes, though methodological quality varied among studies \cite{joschko_active_2024}. Specific populations have demonstrated particularly promising results. Meta-analyses have shown beneficial effects for individuals with post-traumatic stress disorder \cite{wang_colors_2025}, large effect sizes for group art therapy interventions among children and adolescents \cite{kong_meta-analysis_2024}, and significant reductions in anxiety symptoms in pediatric populations \cite{zhou_effects_2023}. For individuals with schizophrenia, the evidence presents a more nuanced picture. While the NICE Guidelines indicate that arts therapies are effective in reducing negative symptoms compared to control conditions \cite{noauthor_overview_2014}, and several studies suggest positive effects \cite{montag_pilot_2014, montag_neglected_2017}, the overall evidence base remains inconclusive \cite{attard_art_2016}.

AT has been increasingly influenced by growing digitization \cite{zubala_art_2021}, presenting both opportunities and challenges for practitioners and clients. While digital technologies can enhance client involvement and broaden creative boundaries, they also introduce risks of exclusion due to reduced access and varying levels of digital competence among participants. The potential roles of artificial intelligence (AI) in AT are rapidly evolving and multifaceted. A recent survey by Jütte et al. \cite{jutte_perspectives_2024} of 56 art therapists found that 30\% frequently or occasionally use AI in their practice with patients. AI's therapeutic role exists on a spectrum, ranging from partner in co-creative processes \cite{schmutz_integrating_2024, du_deepthink_2024} to curator of personalized visuals with therapeutic intent \cite{yilma_ai-therapist_nodate}. This spectrum also encompasses varying levels of autonomy, from supportive tools that augment human creativity to autonomous agents capable of independent therapeutic decision-making \cite{zubala_art_2025}. Interestingly, AI approaches for the evaluation of AT imagery have not been explored yet. While most AI research in AT has concentrated on enhancing the therapeutic process itself, AI approaches for evaluating artwork have remained largely unexplored. We believe that AI methods hold significant potential for advancing imagery assessment.

\subsection{Evaluation of art therapy process}

The exploration of the artworks and creative processes provides the art therapist with valuable diagnostic insights and guides the formulation of therapeutic goals and the ongoing conduct of therapy. Nevertheless, traditional methodologies for the standardized evaluation of the visual artistic output in AT \cite{schoch_measuring_2017, cohen_diagnostic_1988, elbing_reliabilitat_2009, hacking_descriptive_1996} focus on rating the articistic output on several predefined scales. These approaches remain rare and are often time-intensive, creating barriers to systematic assessment of therapeutic progress. In addition to this, several attempts have been made to develop approaches for automatic assessment. For example, Gengenbach et al. \cite{gengenbach_artificial_2022} demonstrated that a convolutional neural network could match human ratings of artworks. More recently, Kim et al. \cite{kim_exploring_2024} employed a ResNet model to successfully classify between healthy controls and individuals with anxiety, depression, and schizophrenia based on their mandala drawings.

Contemporary computer vision and multimodal vision-language models present novel methodologies for image evaluation that could revolutionize art therapy assessment. CLIP (Contrastive Language–Image Pretraining), trained on 400 million image-text pairs from publicly available internet sources, employs contrastive learning to associate images with corresponding text \cite{radford_learning_2021}. This approach makes CLIP general-purpose and zero-shot capable across diverse downstream tasks, including aesthetic evaluation \cite{hentschel_clip_2022}. In this paper, we propose a novel method to evaluate the images produced by patients during AT using a longitudinal analysis based on multimodal embeddings. To our knowledge, this represents the first application of multimodal embeddings for evaluating images produced during art therapy sessions. This study addresses the following research questions:

\begin{enumerate}
\item To what extent do CLIP embeddings capture meaningful semantic content in AT imagery?
\item How does semantic similarity between consecutive artworks change over the course of AT sessions?
\item How do individual participants differ in their exploration and occupation of the visual semantic space?
\end{enumerate}

\section{Materials and methods}

\subsection{Longitudinal corpus of images produced during AT}
The study is based on a secondary analysis of visual material produced during a randomized controlled trial (RCT) evaluating the efficacy of psychodynamic group art therapy for individuals with schizophrenia or related psychotic disorders \cite{montag_pilot_2014}. The study was ethically approved and conducted in accordance with the Declaration of Helsinki. The intervention consisted of 12 group sessions delivered over six weeks, with each session lasting 90 minutes. Group size varied between 3 and 6 participants. Sessions took place in a purpose-designed studio space located within the psychiatric clinic, intended to provide a creative environment. The therapeutic model followed a non-directive framework. Participants were free to choose their materials, techniques, and subjects without guidance or thematic prescription. They were encouraged to find their own visual language and proceed at their own pace. The art therapist’s interventions were aimed to supporting the artistic process and facilitating participants' engagement with their imagery as well as the verbal reflection about the art work and its potential meaning, both individually and within the group context. At the end of each session, all artworks were systematically photographed and cataloged. This process yielded a longitudinal image corpus documenting the unfolding of individual and group expression across the treatment period. This dataset serves as the basis for the current AI-based reanalysis.

\subsection{Participants}
Of the 16 participants who completed the intervention, 2 were excluded from the reanalysis because they primarily used clay, producing three-dimensional works that could not be reliably captured through two-dimensional photographs. The remaining 14 participants (female, n = 8; male, n = 6, 12 diagnosed with paranoid schizophrenia (ICD-10 F20.0), one diagnosed with schizoaffective disorder (F25.2) and one with acute polymorphic psychotic disorder (F23.0)) produced a total of 164 artworks during the intervention (mean = 11.7, SD = 7.5). Due to the non-directive approach and the allowance for participants to work at their own pace, there was considerable variation in productivity, ranging from 3 to 30 pieces per individual. The basic sociodemographic and clinical characteristics of the sample are summarized in Table-\ref{tab:summary_stats}.

\begin{table}[ht]
\centering
\begin{tabular}{lrrrrrrr}
\toprule
& Mean & Std & Min & 25\% & 50\% & 75\% & Max \\
\midrule
Age (years) & 36.69 & 10.83 & 24.96 & 28.78 & 33.44 & 42.16 & 58.29 \\
Duration of illness (years) & 11.19 & 10.59 & 0.13 & 5.32 & 8.28 & 14.47 & 40.29 \\
Clorpromazin Equivalents & 377.82 & 237.40 & 80.00 & 200.00 & 300.00 & 587.50 & 800.00 \\
GAF & 38.07 & 13.83 & 10.00 & 30.00 & 37.50 & 47.25 & 60.00 \\
Symptom severity (BPRS) & 34.21 & 10.58 & 19.00 & 26.25 & 33.50 & 41.75 & 53.00 \\
Number of images & 11.71 & 7.50 & 3.00 & 6.25 & 11.00 & 13.00 & 30.00 \\
\bottomrule
\end{tabular}
\caption{Descriptive statistics of demographic, clinical, and artistic variables in the patient sample. Values represent mean, standard deviation, and distributional parameters (minimum, quartiles, maximum) for age, duration of illness, chlorpromazine equivalents, Global Assessment of Functioning (GAF), symptom severity (BPRS), and number of images created.}
\label{tab:summary_stats}
\end{table}

\subsection{Feature Extraction and Formal Analysis}

For the formal analysis of the artwork images, feature extraction was performed using the OpenAI CLIP model, specifically the clip-vit-base-patch32 architecture, accessed via the Hugging Face transformers library \cite{radford_learning_2021}. This model encodes visual content into 512-dimensional embeddings that capture semantic and stylistic features of the images. All computations were carried out on an NVIDIA A100 GPU within the high-performance computing (HPC) cluster environment of our hosting institution. These embeddings served as the basis for subsequent quantitative analyses of the visual material.

Since artworks from people with schizophrenia have not yet been evaluated with CLIP embeddings, we employed a permutation-based validation framework to assess whether these embeddings capture meaningful semantic patterns beyond low-level visual features such as color and texture. We calculated the empirical coherence of the embedding space as the mean cosine distance from individual image embeddings to the group centroid. To test whether observed clustering patterns reflected genuine semantic content rather than superficial visual similarities, we generated a null distribution through 1,000 permutation iterations. In each iteration, we spatially altered the original images by randomly shuffling pixel values while preserving the overall color distribution, then re-encoded these spatially randomized images through the CLIP model. If CLIP embeddings primarily captured color or texture information, "scrambled" images would yield similar coherence values to the originals. Conversely, if embeddings captured higher-order semantic features, pixel-permuted images would show significantly different (typically higher) coherence values, indicating loss of meaningful structure. Statistical significance was assessed by comparing observed coherence against the null distribution. To visualize the embedding space structure, we performed t-distributed Stochastic Neighbor Embedding (t-SNE) dimensionality reduction on the 512-dimensional CLIP embeddings and plotted the resulting two-dimensional representation with actual images positioned at their corresponding coordinates. This visualization approach allowed for qualitative assessment of whether semantically similar images clustered together in the reduced space, providing complementary evidence to the quantitative permutation test that subsequent analyses were based on semantic content rather than confounding low-level visual features.

To quantify intra- and interindividual variation in image embeddings, we computed pairwise cosine distances between all embeddings using sklearn.metrics.pairwise.cosine\_distances \cite{scikit-learn}. Each embedding was labeled by participant ID. We then categorized distances as either within-subject or between-subject and compared these groups using one-way ANOVA and variance ratio analysis.

To examine longitudinal trends in visual semantic change, we computed two sets of cosine distance scores based on the CLIP embeddings for each participant. The first set captured the similarity between the participant’s first image and each of their subsequent images, providing a measure of cumulative semantic drift over time. Each \( d_j \) captures the semantic distance between image \( j \) and image \( j+1 \), enabling longitudinal modeling or step-wise analysis rather than aggregating over the entire sequence.
\[
Distance\ to\ next\ image = 1 - \frac{x_j \cdot x_{j+1}}{\|x_j\| \, \|x_{j+1}\|}, \quad \text{for } j = 1, \dots, n-1
\] The second set measured the similarity between each image and the one immediately following it, reflecting local semantic continuity across sessions.
\[
Distance\ form\ first\ image = 1 - \frac{x_1 \cdot x_{j+1}}{\|x_1\| \, \|x_{j+1}\|}, \quad \text{for } j = 1, \dots, n-1
\] These similarity scores $\{d_1, d_2, \dots, d_{n-1}\}$ served as outcome variables in two separate linear mixed-effects models. In both models, image position in the sequence was included as a fixed effect to estimate change over time, while participant identity was modeled as a random intercept to account for inter-individual variability.

In a final exploratory analysis, we aimed to estimate how individual participants behave within the abstract visual semantic space defined by their embeddings. To capture individual-level differences in how semantically broad or narrow these representational spaces are, we characterized the spread and volume of each participant's embeddings. Unlike measures such as mean cosine similarity, which assess semantic coherence by quantifying directional alignment between vectors, this approach focused on distributional dispersion—i.e., how widely embeddings are spatially distributed—using metrics that are sensitive to both direction and magnitude. To facilitate interpretability and reduce computational complexity, high-dimensional embeddings were first projected into a lower-dimensional space using Principal Component Analysis (PCA). For each participant, we then extracted their PCA-reduced vectors and computed two complementary diversity metrics: spread, defined as the sum of standard deviations across all PCA dimensions, and volume, calculated as the product of the peak-to-peak (max–min) ranges along each axis, estimating the size of the hyperrectangle enclosing the embedding distribution. Together, these metrics provide a scale-sensitive characterization of individual variability in semantic space exploration. All computations were performed using the Python libraries scikit-learn and statsmodels \cite{scikit-learn, seabold2010statsmodels}.

\section{Results}

\subsection{CLIP Embedding Validation}

To validate that CLIP embeddings capture meaningful semantic patterns rather than superficial visual features in the dataset of AT images produced by people with schizophrenia, we conducted a permutation-based statistical analysis. The observed coherence of real images in CLIP embedding space was 0.2290 (mean cosine distance to centroid), significantly higher than the null distribution generated from spatially scrambled images (mean = 0.0896, SD = 0.0010; p = 0.0099). This significant difference demonstrates that randomly altered images clustered much more tightly in embedding space than semantically intact images. In addition to this, the t-SNE dimensionality reduction visualization of the 512-dimensional CLIP embeddings corroborated the quantitative findings. Real images were distributed across distinct regions of the two-dimensional space, with semantically similar images (e.g., landscapes, portraits, abstract expressions, flowers and plants) forming loose clusters. This spatial organization in the reduced dimensional space provided qualitative confirmation that CLIP embeddings successfully captured meaningful semantic relationships within the AT image collection.

We observed a highly significant effect of subject identity on embedding similarity: within-subject distances were significantly lower than between-subject distances (ANOVA: $F(1,9739) = 271.24$, $p < 0.00001)$. However, the variance of within-subject distances was similar to that of between-subject distances (variance ratio = 0.96), suggesting that while embeddings are reliably more similar within individuals, the dispersion of distances is comparable across both groups.

\begin{figure}[t!]
\centering
\includegraphics[width=0.8\linewidth]{figures/all.png}
\caption{t-SNE visualization of the dataset.}
\label{fig:t-sne}
\end{figure}

\subsection{Longitudinal Analysis of Visual Semantic Evolution}

We computed the semantic distance between consecutive images for each participant by calculating the cosine distance between pairs of embeddings, which were sorted by participant ID and image sequence number, and missing values for the last image in each sequence were handled appropriately. Both the predictor (image position) and outcome (cosine distance) variables were standardized using z-score normalization prior to modeling.

A linear mixed-effects model was then fitted, predicting standardized semantic distance between two consecutive embeddings from standardized image position, with participant included as a random intercept. The model showed a significant positive association between image position and semantic distance ($\beta = 0.284$, $SE = 0.085$, $z = 3.33$, $p = 0.001$), indicating that the semantic difference between consecutive images increased as the intervention progressed. Random intercept variance ($\sigma^2 = 0.310$) reflected moderate variability between participants.

To examine broader semantic drift over time, we calculated the cosine distance between each image and the participant’s first image. Embeddings were standardized, and a linear mixed-effects model was fitted with image position as a fixed effect and participant as a random intercept. The model revealed a significant positive effect of image position on semantic distance from the first image ($\beta = 0.336$, $SE = 0.080$, $z = 4.19$, $p < 0.001$), suggesting a cumulative increase in visual-semantic deviation as the intervention progressed. The intercept was not significant ($\beta = 0.115$, $p = 0.499$). Between-participant variance was estimated at 0.315, indicating moderate inter-individual variability in the degree of semantic change.

\begin{figure}[t!]
\centering
\includegraphics[width=0.4\linewidth]{figures/sem_dist_next.png}
\includegraphics[width=0.4\linewidth]{figures/sem_dist_first.png}
\caption{Semantic distance patterns in artwork over the course of art therapy intervention.}
\label{fig:example_bigger}
\end{figure}

\subsection{Semantic Space Exploration}

Analysis of participants' exploration within the CLIP embedding space revealed substantial individual differences in both the breadth and scope of semantic territories covered. The spread metric, which quantifies the distributional dispersion of embeddings across PCA dimensions, showed relatively consistent values across participants ($M = 34.7$, $SD = 4.1$, $range = 28.1-41.4$). This suggests that while participants varied in the specific semantic content they explored, the overall extent of their exploration within the reduced dimensional space was fairly uniform.

In contrast, the volume metric---representing the size of the hyperrectangle enclosing each participant's embedding distribution---demonstrated much greater variability ($M = 1.13 \times 10^{11}$, $SD = 2.05 \times 10^{11}$). The volume scores spanned several orders of magnitude, from $9.41 \times 10^7$ to $7.36 \times 10^{11}$, indicating dramatic differences in the semantic space occupied by different participants. Figure \ref{fig:example_3x2} shows barplots for spread and volume of semantic space exploration across all participants (panels A-B), alongside t-SNE visualizations of image sequences for four exemplary participants (panels C-F). These examples illustrate contrasting patterns of semantic exploration: participants 42 and 33 demonstrate extensive semantic territory exploration with images distributed across large volumes of semantic space, while participants 21 and 35 show more constrained exploration with images remaining relatively tightly clustered within smaller semantic territories. Each point represents an individual artwork, with connecting lines indicating temporal sequence progression through the therapeutic intervention.

\begin{figure}[t!]
\centering

\includegraphics[width=0.4\linewidth]{figures/diversity_spread.png}
\includegraphics[width=0.4\linewidth]{figures/diversity_volume.png}\\[0.5em]

\includegraphics[width=0.4\linewidth]{figures/t-SNE_Art_Therapy_Trajectory_Participant_42.png}
\includegraphics[width=0.4\linewidth]{figures/t-SNE_Art_Therapy_Trajectory_Participant_33.png}\\[0.5em]

\includegraphics[width=0.4\linewidth]{figures/t-SNE_Art_Therapy_Trajectory_Participant_21.png}
\includegraphics[width=0.4\linewidth]{figures/t-SNE_Art_Therapy_Trajectory_Participant_35.png}
\caption{\textbf{Individual differences in semantic space exploration during art therapy.}}
\label{fig:example_3x2}
\end{figure}

\section{Discussion}

This study represents the first application of multimodal embeddings for evaluating artistic output in AT, addressing a critical methodological gap. Traditional assessment methods for visual artistic expression remain rare and time-intensive \cite{schoch_measuring_2017, cohen_diagnostic_1988, elbing_reliabilitat_2009, hacking_descriptive_1996}, creating barriers to systematic evaluation of therapeutic progress.

Our validation approach demonstrates that CLIP embeddings capture high-level semantic content rather than superficial visual features. When semantic structure was destroyed through pixel-level permutations while preserving color information, the resulting images produced highly similar embeddings that clustered together. In contrast, real art therapy images with diverse semantic content exhibited much greater dispersion across the embedding space. The embeddings also captured unique artistic styles of individual participants.

These validation results establish that our analyses are based on genuine semantic content rather than visual artifacts, supporting CLIP embeddings as a robust foundation for understanding thematic patterns in therapeutic artistic expression.

The longitudinal analysis reveals compelling patterns in the therapeutic process. The progressive increase in semantic distance between consecutive images suggests that art therapy facilitates expanding creative expression over time, with participants exploring increasingly diverse semantic territories rather than repeating similar visual themes.

This expanding creativity may reflect the therapeutic process as patients become more comfortable expressing varied emotions, enhanced cognitive flexibility enabling exploration of diverse visual concepts, and deepening self-exploration as individuals access broader psychological territories through artistic expression.

We also examined how participants occupy abstract visual semantic space throughout their therapeutic journey. The contrasting patterns between spread and volume metrics suggest that participants differed primarily in the range extremes of their semantic exploration rather than in overall distributional characteristics. While most participants showed similar patterns of dispersion around their central semantic tendencies (as indicated by consistent spread values), a subset demonstrated markedly expanded exploration boundaries (as captured by the highly variable volume metric). This finding indicates that individual differences in art therapy may be characterized less by different styles of exploration and more by differences in the boundaries of semantic territories accessed during the therapeutic process.

CLIP embeddings offer significant advantages over traditional evaluation methods by providing objective, scalable, and reproducible measures of artistic expression without requiring extensive training or subjective interpretation. This could facilitate systematic documentation of therapeutic progress, enable larger-scale research studies, and support real-time treatment monitoring.

Our findings may hold particular relevance for schizophrenia treatment, a domain in which cognitive flexibility and self-expression are often impaired. The progressive semantic diversification observed in participants’ artwork may indicate therapeutic gains, such as enhanced cognitive flexibility, greater expressive range, and improved adaptive functioning. However, it remains to be established how changes in CLIP ratings relate to variations in psychopathological symptoms or cognitive performance. At this stage of research, it cannot yet be determined whether these changes correspond to clinical improvement or deterioration. Longitudinal studies integrating standardized clinical and cognitive assessments are needed to elucidate the relationship between semantic variability in artwork and therapeutic outcomes.

This work opens several promising directions for future research and clinical application. The findings suggest the potential for developing automated assessment tools that could make art therapy evaluation more objective, accessible, and scalable, thereby broadening the reach and impact of creative therapies in clinical settings. Real-time monitoring of semantic exploration could offer clinicians objective feedback on therapeutic progress. The methodological framework introduced here could also be extended to other forms of creative expression, such as music therapy or creative writing, offering a broader perspective on the role of artistic processes in mental health treatment.

\section{Conclusions}
This study demonstrates that multimodal embeddings provide a powerful new methodology for evaluating artistic expression in AT. The progressive semantic diversification observed in participants' artwork provides objective evidence for therapeutic change and creative growth over time. The substantial individual differences in semantic exploration patterns suggest opportunities for personalized treatment approaches based on creative trajectory analysis. These findings establish a foundation for more systematic, objective, and scalable evaluation of art therapy interventions, with potential applications across diverse clinical populations and therapeutic settings.

\section{Limitations}
This study has several limitations. First, the dataset is relatively small, which may constrain the generalizability and robustness of the findings. Second, the sample consists exclusively of participants diagnosed with psychotic disorders, limiting the applicability of results to other clinical or non-clinical populations. Third, the study lacked a control group, making it difficult to disentangle the effects of AT from other factors such as spontaneous symptom fluctuation or nonspecific therapeutic influences. Additionally, while we demonstrated significant semantic changes over time, we did not directly correlate these changes with clinical outcomes or symptom measures. Future research should examine whether semantic trajectory patterns predict treatment response or clinical improvement. Finally, the analysis was based on a single model (CLIP-ViT-B/32); future research should compare the performance of alternative vision–language models to assess consistency and potential model-specific biases.

\section{Acknowledgments}
I.N. is a participant in the BIH Charité Digital Clinician Scientist Program funded by the Charité – Universitätsmedizin Berlin and the Berlin Institute of Health at Charité (BIH). The authors acknowledge the Scientific Computing of the IT Division at the Charité - Universitätsmedizin Berlin for providing computational resources
that have contributed to the research results reported in this paper.

\printbibliography

\end{document}