<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>The Latin Language Evolved Over Time, Masked Models Disregard
That</title>
  <link rel="preconnect" href="https://fonts.googleapis.com">
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
  <link href="https://fonts.googleapis.com/css2?family=Tinos:ital,wght@0,400;0,700;1,400;1,700&display=swap" rel="stylesheet">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/bulma/0.9.4/css/bulma.min.css">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.0/css/all.min.css">
  <link rel="stylesheet" href="../../../css/site.css">

  <!-- citation information -->
  <link rel="canonical" href="https://anthology.ach.org/volumes/vol0003/the-latin-language-evolved-over-time-masked-models/">
  <meta name="citation_title" content="The Latin Language Evolved Over Time, Masked Models Disregard
That">
  <meta name="citation_date" content="2025">
  <meta name="citation_public_url" content="https://anthology.ach.org/volumes/vol0003/the-latin-language-evolved-over-time-masked-models/">
  <meta name="citation_journal_title" content="Anthology of Computers and the Humanities">
  <meta name="citation_issn" content="">
  <meta name="citation_volume" content="3">
  <meta name="citation_firstpage" content="1336">
  <meta name="citation_lastpage" content="1347">
  <meta name="citation_doi" content="10.63744/sLAHYnQdA8fu">
  <meta name="citation_author" content="Cuscito, Miriam">
  <meta name="citation_author" content="Ferrara, Alfio">
  <meta name="citation_author" content="Ruskov, Martin">
  <meta name="citation_editor" content="Arnold, Taylor">
  <meta name="citation_editor" content="Fantoli, Margherita">
  <meta name="citation_editor" content="Ros, and Ruben">
  <meta name="citation_abstract" content="Training of Latin language models is rarely done with consideration
of important historical watersheds.&lt;/p&gt;
&lt;p&gt;Here we demonstrate how this leads to a poor performance when
specific socio-temporal contextualisation is sought, something common to
humanities research. We perform an evaluation that compares the
historical adequacy of Latin language models, i.e. their ability to
generate tokens, representative for a historical period.&lt;/p&gt;
&lt;p&gt;We adopt a previously established method and refine it to overcome
limitations due to Latin being an under-resourced language and one with
intense tradition of intertextuality. To do this we extract word lists
and concordances from the LatinISE corpus and use them to compare seven
masked language models trained for Latin. We further perform statistical
analysis of the results in order to identify the best and worst
performing models in each of the historical contexts of interest.&lt;/p&gt;
&lt;p&gt;We show that BERT medieval multilingual best captures the Classical
linguistic context. Four models are indistinguishably good in our
evaluation of the the Neo-Latin linguistic context.&lt;/p&gt;
&lt;p&gt;These findings have broad implications for wider historical language
research and beyond. Among these, we emphasise the need to train
historical language models with due attention on consistent historical
periods and we discuss the possible usefulness of noisy predictions.
Historical research of language models provides a neat demonstration of
how model biases could impact their performance in specific domains.">
  <meta name="citation_language" content="en">
  <meta name="citation_keywords" content="historical adequacy; algorithmic bias; masked language models; Latin language; model evaluation">
  <meta name="citation_fulltext_html_url" content="https://anthology.ach.org/volumes/vol0003/the-latin-language-evolved-over-time-masked-models/">
  <meta name="citation_pdf_url" content="https://anthology.ach.org/volumes/vol0003/the-latin-language-evolved-over-time-masked-models/10.63744@sLAHYnQdA8fu.pdf">

  <!-- Lightbox CSS -->
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/lightbox2/2.11.4/css/lightbox.min.css" />

  <!-- Pandoc syntax highlighting CSS -->
  <link rel="stylesheet" href="../../../css/syntax-highlighting.css" />
  <link rel="stylesheet" href="../../../css/article.css" />


</head>
<body>
  <!-- Navigation Bar -->
  <nav class="navbar" role="navigation" aria-label="main navigation">
    <div class="navbar-brand">
      <a class="navbar-item" href="https://ach.org">
        <img src="../../../logo/logo.png" alt="ACH Logo">
      </a>

      <a role="button" class="navbar-burger" aria-label="menu" aria-expanded="false" data-target="navbarMain">
        <span aria-hidden="true"></span>
        <span aria-hidden="true"></span>
        <span aria-hidden="true"></span>
      </a>
    </div>

    <div class="navbar-menu" id="navbarMain">
      <div class="navbar-start">
      </div>
      <div class="navbar-end">
        <a class="navbar-item" href="https://anthology.ach.org/">
          <b>Home</b>
        </a>
        <a class="navbar-item" href="https://anthology.ach.org/volumes/">
          <b>Volumes</b>
        </a>
        <a class="navbar-item" href="https://anthology.ach.org/about">
          <b>About</b>
        </a>
        <span style="width: 25px"></span>
      </div>
    </div>
  </nav>

  <!-- Hero Section -->
  <section class="hero">
    <div class="hero-body">
      <div class="container">
        <p class="subtitle is-6 has-text-grey">Anthology of Computers and the Humanities · <a href="..">Volume 3</a></p>
        <h1 class="title paper-title">The Latin Language Evolved Over Time, Masked Models Disregard
That</h1>

        <div class="is-size-5 pl-7 has-text-centered">
          <a href="https://creativecommons.org/licenses/by/4.0/?ref=chooser-v1" target="_blank" rel="license noopener noreferrer" style="display:inline-block;"><img style="height:25px!important;margin-left:3px;vertical-align:text-bottom;" src="../../../logo/cc-by.png"></a>
        </div>
      </div>

    </div>
  </section>

  <!-- Main Content -->
  <section class="section">
    <div class="container">

      <div class="paper-meta">
        <div class="authors-container">
          <div class="authors">
            <section class="authors-block">
              <p class="authors">
                  <span class="author">
                    Miriam Cuscito<sup>1</sup><a class="orcid-link" href="https://orcid.org/0009-0003-9585-2803" target="_blank" rel="noopener">
                        <img class="orcid" src="../../../logo/orcid.png" alt="ORCID">
                      </a>
                  </span>,
                  <span class="author">
                    Alfio Ferrara<sup>2</sup><a class="orcid-link" href="https://orcid.org/0000-0002-4991-4984" target="_blank" rel="noopener">
                        <img class="orcid" src="../../../logo/orcid.png" alt="ORCID">
                      </a>
                  </span> and
                  <span class="author">
                    Martin Ruskov<sup>3</sup><a class="orcid-link" href="https://orcid.org/0000-0001-5337-0636" target="_blank" rel="noopener">
                        <img class="orcid" src="../../../logo/orcid.png" alt="ORCID">
                      </a>
                  </span>
              </p>

              <ul class="affiliations">
                  <li><sup>1</sup> Department of Languages, Literatures, Cultures and Mediations,
University of Milan, Milan, Italy</li>
                  <li><sup>2</sup> Department of Informatics, University of Milan, Milan, Italy</li>
                  <li><sup>3</sup> Department of Languages and Modern Cultures, University of Genoa,
Genoa, Italy</li>
              </ul>
            </section>

          </div>
        </div>
      </div>


      <!-- Download Buttons -->
      <div class="buttons-container">
        <a href="10.63744@sLAHYnQdA8fu.pdf" class="button is-primary" target="_blank">
          <span class="icon">
            <i class="fas fa-file-pdf"></i>
          </span>
          <span>Download PDF</span>
        </a>
        <a href="10.63744@sLAHYnQdA8fu.bib" class="button is-info" target="_blank">
          <span class="icon">
            <i class="fas fa-file-code"></i>
          </span>
          <span>Download Citation</span>
        </a>
        
      </div>

      <!-- DOI -->
      <div class="doi-box">
        <p class="is-size-6">
          <b>Permanent Link:</b> <a class="doi-link" href="https://doi.org/10.63744/sLAHYnQdA8fu" target="_blank">https://doi.org/10.63744/sLAHYnQdA8fu</a>
        </p>
        <p class="is-size-6">
          <b>Published:</b> 21 November 2025
        </p>
        <p class="is-size-6">
          <b>Keywords:</b> historical adequacy, algorithmic bias, masked language models, Latin language, model evaluation
        </p>
      </div>

      <!-- Abstract -->
      <div class="content">
         <div class="abs"><span>Abstract</span><p>Training of Latin language models is rarely done with consideration of important historical watersheds. Here we demonstrate how this leads to a poor performance when specific socio-temporal contextualisation is sought, something common to humanities research. We perform an evaluation that compares the historical adequacy of Latin language models, i.e. their ability to generate tokens, representative for a historical period. We adopt a previously established method and refine it to overcome limitations due to Latin being an under-resourced language and one with intense tradition of intertextuality. To do this we extract word lists and concordances from the LatinISE corpus and use them to compare seven masked language models trained for Latin. We further perform statistical analysis of the results in order to identify the best and worst performing models in each of the historical contexts of interest. We show that BERT medieval multilingual best captures the Classical linguistic context. Four models are indistinguishably good in our evaluation of the the Neo-Latin linguistic context. These findings have broad implications for wider historical language research and beyond. Among these, we emphasise the need to train historical language models with due attention on consistent historical periods and we discuss the possible usefulness of noisy predictions. Historical research of language models provides a neat demonstration of how model biases could impact their performance in specific domains.</p></div>


      </div>

    </div>
  </section>

  <!-- Footer -->
  <footer class="footer">
    <div class="content has-text-centered">
      <p>
        <strong>Anthology of Computers and the Humanities</strong> · Association for Computers and the Humanities · Austin, Texas, U.S.A.
      </p>
      <p class="is-size-7">
        Paper © 2025 the authors. All other content © 2025 ACH.
      </p>
    </div>
  </footer>


  <!-- Lightbox JavaScript -->
  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/lightbox2/2.11.4/js/lightbox.min.js"></script>

  <!-- Prism.js for syntax highlighting -->
  <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.30.0/prism.min.js"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.30.0/components/prism-python.min.js"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.30.0/components/prism-bash.min.js"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.30.0/components/prism-xml.min.js"></script>

  <!-- Custom JavaScript -->
  <script src="../../../js/navbar.js"></script>
  <script src="../../../js/lightbox-config.js"></script>
  <script src="../../../js/code-copy.js"></script>

</body>
</html>